# 数据重塑透视

## 重塑透视

数据的重塑简单说就是对原数据进行变形，为什么需要变形，因为当前数据的展示形式不是我们期望的维度，也可以说索引不符合我们的需求。

对数据的重塑不是仅改变形状那么简单，在变形过程中，数据的内在数据意义不能变化，但数据的提示逻辑则发生了重大的改变。

主要操作

Pandas 主要提供以下数据变形方面的操作：

- 透视 df.pivot / pd.pivot_table
- 堆叠 stacking / unstacking
- 数据融合 (melt)
- 交叉表 crosstab()
- 分解 pd.factorize(x, sort=True)
- 虚拟对象 pd.get_dummies(df)
- 爆炸 df.explode('values')
- 窗口计算 rolling() expanding()

## 数据透视 Pivot Table

### 整理透视表

可以看一下它的逻辑：

![image-20230427134918556](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20230427134918556.png)

这里有三个参数，作用分别是：

- index：新 df 的索引列，用于分组，如果为None，则使用现有索引
- columns：新 df 的列，如果透视后有重复值会报错
- values：用于填充 df 的列。 如果未指定，将使用所有剩余的列，并且结果将具有按层次结构索引的列

### 整理透视案例 [pivot](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pivot.html?highlight=pivot#pandas.DataFrame.pivot)

```python
df = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two',
                           'two'],
                   'bar': ['A', 'B', 'C', 'A', 'B', 'C'],
                   'baz': [1, 2, 3, 4, 5, 6],
                   'zoo': ['x', 'y', 'z', 'q', 'w', 't']})
'''
    foo   bar  baz  zoo
0   one   A    1    x
1   one   B    2    y
2   one   C    3    z
3   two   A    4    q
4   two   B    5    w
5   two   C    6    t
'''
# 透视
df.pivot(index='foo', columns='bar', values='baz')
'''
bar  A   B   C
foo
one  1   2   3
two  4   5   6
'''
# 多层索引，取其中一列
df.pivot(index='foo', columns='bar')['baz']
'''
bar  A   B   C
foo
one  1   2   3
two  4   5   6
'''
# 指定值
df.pivot(index='foo', columns='bar', values=['baz', 'zoo'])
'''
baz       zoo
bar   A  B  C   A  B  C
foo
one   1  2  3   x  y  z
two   4  5  6   q  w  t
'''
```

![image-20230427135401358](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20230427135401358.png)

### 聚合透视 Pivot Table

`df.pivot()` 只能将数据进行整理，如果遇到重复值要进行聚合计算，就要用到`pd.pivot_table()`。它可以实现类似 Excel 那样的高级数据透视功能。

![image-20230427135445046](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20230427135445046.png)

一些参数介绍：

- data: 要透视的 DataFrame 对象
- values: 要聚合的列或者多个列
- index: 在数据透视表索引上进行分组的键
- columns: 在数据透视表列上进行分组的键
- aggfunc: 用于聚合的函数, 默认是 numpy.mean



### 聚合透视案例

```python
df = pd.DataFrame({"A": ["foo", "foo", "foo", "foo", "foo",
                         "bar", "bar", "bar", "bar"],
                   "B": ["one", "one", "one", "two", "two",
                         "one", "one", "two", "two"],
                   "C": ["small", "large", "large", "small",
                         "small", "large", "small", "small",
                         "large"],
                   "D": [1, 2, 2, 3, 3, 4, 5, 6, 7],
                   "E": [2, 4, 5, 5, 6, 6, 8, 9, 9]})
df
'''
     A    B      C  D  E
0  foo  one  small  1  2
1  foo  one  large  2  4
2  foo  one  large  2  5
3  foo  two  small  3  5
4  foo  two  small  3  6
5  bar  one  large  4  6
6  bar  one  small  5  8
7  bar  two  small  6  9
8  bar  two  large  7  9
'''
```

将 D 列值加和，索引为 AB，列为 C 不去重值：

```python
table = pd.pivot_table(df, values='D', index=['A', 'B'],
                    columns=['C'], aggfunc=np.sum)
table
'''
C        large  small
A   B
bar one    4.0    5.0
    two    7.0    6.0
foo one    4.0    1.0
    two    NaN    6.0
'''
```

空值的传入：

```python
table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],
                    aggfunc={'D': np.mean,
                             'E': np.mean})
```

不同值使用不同的聚合计算方式：

```python
table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],
                    aggfunc={'D': np.mean,
                             'E': [min, max, np.mean]})
```

汇总边际，给列的每层加一个 all 列进行汇总，计算方式与 aggfunc 相同。

```python
pd.pivot_table(df, values='D', index=['A', 'B'],
               columns=['C'],  aggfunc=np.sum,
               margins=True)
```

## 数据堆叠 Stack

### 堆叠和取消堆叠

![image-20230427140304381](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20230427140304381.png)

![image-20230427140320617](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20230427140320617.png)

这些方法本质上是：

- stack：“透视”某个级别的（可能是多层的）列标签，返回带有索引的 DataFrame，该索引带有一个新的最里面的行标签。
- unstack：（堆栈的逆操作）将（可能是多层的）行索引的某个级别“透视”到列轴，从而生成具有新的最里面的列标签级别的重构的 DataFrame。

stack 过程将数据集的列转行，unstack 过程为行转列。

上例中，原始数据集索引有两层，堆叠过程就是将最列转到最内测的行上，unstack 是将最内层的行转移到最内层的列索引中。



### 堆叠 [stack](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.stack.html?highlight=stack#pandas.DataFrame.stack)

单层索引：

```python
df_single_level_cols = pd.DataFrame([[0, 1], [2, 3]],
                                    index=['cat', 'dog'],
                                    columns=['weight', 'height'])
df_single_level_cols
'''
weight height
cat       0      1
dog       2      3
'''

df_single_level_cols.stack()
'''
cat  weight    0
     height    1
dog  weight    2
     height    3
dtype: int64
'''
```

多层索引：

```python
multicol1 = pd.MultiIndex.from_tuples([('weight', 'kg'),
                                       ('weight', 'pounds')])
df_multi_level_cols1 = pd.DataFrame([[1, 2], [2, 4]],
                                    index=['cat', 'dog'],
                                    columns=multicol1)

df_multi_level_cols1
'''
weight
         kg    pounds
cat       1        2
dog       2        4
'''

df_multi_level_cols1.stack()
'''
weight
cat kg           1
    pounds       2
dog kg           2
    pounds       4
'''
```

缺失值：

```python
multicol2 = pd.MultiIndex.from_tuples([('weight', 'kg'),
                                       ('height', 'm')])
df_multi_level_cols2 = pd.DataFrame([[1.0, 2.0], [3.0, 4.0]],
                                    index=['cat', 'dog'],
                                    columns=multicol2)

df_multi_level_cols2
'''
weight height
        kg      m
cat    1.0    2.0
dog    3.0    4.0
'''

df_multi_level_cols2.stack()
'''
height  weight
cat kg     NaN     1.0
    m      2.0     NaN
dog kg     NaN     3.0
    m      4.0     NaN
'''
```

指定索引层级：

```python
df_multi_level_cols2.stack(0)
'''
kg    m
cat height  NaN  2.0
    weight  1.0  NaN
dog height  NaN  4.0
    weight  3.0  NaN
'''

df_multi_level_cols2.stack([0, 1])
'''
cat  height  m     2.0
     weight  kg    1.0
dog  height  m     4.0
     weight  kg    3.0
dtype: float64
'''
```

删除缺失值：

```python
df_multi_level_cols3 = pd.DataFrame([[None, 1.0], [2.0, 3.0]],
                                    index=['cat', 'dog'],
                                    columns=multicol2)

df_multi_level_cols3
'''
weight height
        kg      m
cat    NaN    1.0
dog    2.0    3.0
'''

df_multi_level_cols3.stack(dropna=False)
'''
height  weight
cat kg     NaN     NaN
    m      1.0     NaN
dog kg     NaN     2.0
    m      3.0     NaN
'''

df_multi_level_cols3.stack(dropna=True)
'''
height  weight
cat m      1.0     NaN
dog kg     NaN     2.0
    m      3.0     NaN
'''
```

### 取消堆叠 [unstack](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.unstack.html?highlight=unstack#pandas.DataFrame.unstack)

```python
index = pd.MultiIndex.from_tuples([('one', 'a'), ('one', 'b'),
                                   ('two', 'a'), ('two', 'b')])
s = pd.Series(np.arange(1.0, 5.0), index=index)
s
'''
one  a   1.0
     b   2.0
two  a   3.0
     b   4.0
dtype: float64
'''

s.unstack(level=-1)
'''
a   b
one  1.0  2.0
two  3.0  4.0
'''

s.unstack(level=0)
'''
one  two
a  1.0   3.0
b  2.0   4.0
''

df = s.unstack(level=0)
df.unstack()
'''
one  a  1.0
     b  2.0
two  a  3.0
     b  4.0
dtype: float64
'''
```

## 交叉表 Crosstab

### 逻辑图示

![image-20230427141413978](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20230427141413978.png)

### 语法结构

语法结构如下：

```python
pd.crosstab(index, columns, values=None, rownames=None,
colnames=None, aggfunc=None, margins=False,
margins_name: str = 'All', dropna: bool = True,
normalize=False) → 'DataFrame'
```

参数说明：

- index：类数组，在行中按分组的值。
- columns：类数组的值，用于在列中进行分组。
- values：类数组的，可选的，要根据因素汇总的值数组。
- aggfunc：函数，可选，如果未传递任何值数组，则计算频率表。
- rownames：序列，默认为None，必须与传递的行数组数匹配。
- colnames：序列，默认值为None，如果传递，则必须与传递的列数组数匹配。
- margins：布尔值，默认为False，添加行/列边距（小计）
- normalize：布尔值，{'all'，'index'，'columns'}或{0,1}，默认为False。 通过将所有值除以值的总和进行归一化。

### 案例

在下例中，A B 两列进行交叉，A 有不重复的值 1和2，B 有3和4。交叉后组成了新的数据，具体的值为对应行列上的组合在原数据中的数量。

```python
df = pd.DataFrame({'A': [1, 2, 2, 2, 2],
                   'B': [3, 3, 4, 4, 4],
                   'C': [1, 1, np.nan, 1, 1]})
'''
   A  B    C
0  1  3  1.0
1  2  3  1.0
2  2  4  NaN
3  2  4  1.0
4  2  4  1.0
'''

pd.crosstab(df['A'], df['B'])
'''
B  3  4
A
1  1  0
2  1  3
'''
```

可以对 `Categorical` 分类类型数据进行交叉：

```python
foo = pd.Categorical(['a', 'b'], categories=['a', 'b', 'c'])
bar = pd.Categorical(['d', 'e'], categories=['d', 'e', 'f'])
pd.crosstab(foo, bar)
'''
col_0  d  e
row_0
a      1  0
b      0  1
'''
```

### 归一化

对交叉结果进行归一化：

```python
pd.crosstab(df['A'], df['B'], normalize=True)
'''
B    3    4
A
1  0.2  0.0
2  0.2  0.6
'''
```

对每列进行归一化：

```python
pd.crosstab(df['A'], df['B'], normalize='columns')
'''
B    3    4
A
1  0.5  0.0
2  0.5  1.0
'''
```

### 聚合

指定列做为值，并将这些值按一定算法进行聚合：

```python
pd.crosstab(df['A'], df['B'], values=df['C'], aggfunc=np.sum)
'''
B    3    4
A
1  1.0  NaN
2  1.0  2.0
'''
```

### 边距汇总

在最右边增加一个汇总列：

```python
pd.crosstab(df['A'], df['B'],
            values=df['C'],
            aggfunc=np.sum,
            normalize=True,
            margins=True)

'''
B       3    4   All
A
1    0.25  0.0  0.25
2    0.25  0.5  0.75
All  0.50  0.5  1.00
'''
```

## 数据融合 Melt

### 逻辑图示

![image-20230427142241006](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20230427142241006.png)

### 语法结构

具体语法结构如下：

```python
pd.melt(frame: pandas.core.frame.DataFrame,
        id_vars=None, value_vars=None,
        var_name='variable', value_name='value',
        col_level=None)
```

其中：

- id_varstuple，list或ndarray（可选），用作标识变量的列。
- value_varstuple，列表或ndarray，可选，要取消透视的列。 如果未指定，则使用未设置为id_vars的所有列。
- var_namescalar，用于“变量”列的名称。 如果为None，则使用frame.columns.name或“variable”。
- value_namescalar，默认为“ value”，用于“ value”列的名称。
- col_levelint或str，可选，如果列是MultiIndex，则使用此级别来融化。



### pd.melt 示例 [melt](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.melt.html?highlight=melt#pandas.DataFrame.melt)

```python
df = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},
                   'B': {0: 1, 1: 3, 2: 5},
                   'C': {0: 2, 1: 4, 2: 6}})
df
'''
   A  B  C
0  a  1  2
1  b  3  4
2  c  5  6
'''

pd.melt(df, id_vars=['A'], value_vars=['B'])
'''
   A variable  value
0  a        B      1
1  b        B      3
2  c        B      5

'''
pd.melt(df, id_vars=['A'], value_vars=['B', 'C'])
'''
   A variable  value
0  a        B      1
1  b        B      3
2  c        B      5
3  a        C      2
4  b        C      4
5  c        C      6
'''
```

变量列和值列的名称可以自定义:

```python
pd.melt(df, id_vars=['A'], value_vars=['B'],
        var_name='myVarname', value_name='myValname')
'''
   A myVarname  myValname
0  a         B          1
1  b         B          3
2  c         B          5
'''
```

多层索引的方法:

```python
df.columns = [list('ABC'), list('DEF')]
df
'''
   A  B  C
   D  E  F
0  a  1  2
1  b  3  4
2  c  5  6
'''

pd.melt(df, col_level=0, id_vars=['A'], value_vars=['B'])
'''
   A variable  value
0  a        B      1
1  b        B      3
2  c        B      5
'''

pd.melt(df, id_vars=[('A', 'D')], value_vars=[('B', 'E')])
'''
  (A, D) variable_0 variable_1  value
0      a          B          E      1
1      b          B          E      3
2      c          B          E      5
'''
```

### 宽表变长表 [wide_to_long](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.wide_to_long.html?highlight=wide_to_long#pandas.wide_to_long)

另一种转换方法是使用 pd.wide_to_long() 面板数据（panel data）便利函数。它不如 melt() 灵活，但更便于用户使用。

```python
dft = pd.DataFrame(
    {
        "A1970": {0: "a", 1: "b", 2: "c"},
        "A1980": {0: "d", 1: "e", 2: "f"},
        "B1970": {0: 2.5, 1: 1.2, 2: 0.7},
        "B1980": {0: 3.2, 1: 1.3, 2: 0.1},
        "X": dict(zip(range(3), np.random.randn(3))),
    }
)


dft["id"] = dft.index
dft
'''
  A1970 A1980  B1970  B1980         X  id
0     a     d    2.5    3.2 -0.121306   0
1     b     e    1.2    1.3 -0.097883   1
2     c     f    0.7    0.1  0.695775   2
'''

pd.wide_to_long(dft, ["A", "B"], i="id", j="year")
'''
                X  A    B
id year
0  1970 -0.121306  a  2.5
1  1970 -0.097883  b  1.2
2  1970  0.695775  c  0.7
0  1980 -0.121306  d  3.2
1  1980 -0.097883  e  1.3
2  1980  0.695775  f  0.1
'''
```

它的语法是 `pandas.wide_to_long(df, stubnames, i, j, sep='', suffix='\\d+')[source]`，使用 stubnames['A'，'B']，此函数希望找到一组或多组格式为A-supfix1，A-supfix2，…，B-supfix1，B-supfix2，….的列，您可以使用 j（例如j='year'）在结果的长格式中指定要调用此后缀的内容。假设这些宽变量的每一行都由i唯一标识（可以是单个列名或列名列表）数据框中的所有剩余变量保持不变。

详情可参考 [pd.wide_to_long()](https://www.gairuo.com/p/pandas-wide-to-long)。

## 虚拟变量 / 哑变量 [get_dummies](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies)

虚拟变量（Dummy Variables） ，又称虚设变量、名义变量或哑变量，用以反映质的属性的一个人工变量，是量化了的自变量，通常取值为0或1。经常用在 one-hot 特征提取。

### 语法结构

语法结构如下：

```python
pd.get_dummies(data, prefix=None,
               prefix_sep='_', dummy_na=False,
               columns=None, sparse=False,
               drop_first=False, dtype=None)
```

其中：

- prefix：新列的前缀
- prefix_sep：新列前缀的连接符
- todo

### 逻辑说明

简单说，`pd.get_dummies()` 是将一个或者多个列的去重值做为新表的列，每个列的值由0和1组成，在原来此位为此列名的值为1，不是的为0，这样就形成了一个由 0 和1 组成的特征矩阵。

虚拟变量/哑变量在特征工程、数据建模、机器学习等领域有非常重要的作用。

```python
df = pd.DataFrame({'key': list('bbacab'), 'data1': range(6)})
df
'''
  key  data1
0   b      0
1   b      1
2   a      2
3   c      3
4   a      4
5   b      5
'''

pd.get_dummies(df['key'])
'''
   a  b  c
0  0  1  0
1  0  1  0
2  1  0  0
3  0  0  1
4  1  0  0
5  0  1  0
'''
```

### 列前缀

用 `prefix` 给新表列名增加前缀：

```python
pd.get_dummies(df['key'], prefix='key')
'''
   key_a  key_b  key_c
0      0      1      0
1      0      1      0
2      1      0      0
3      0      0      1
4      1      0      0
5      0      1      0
'''
```

### DataFrame 使用

可以直接传入 DataFrame 使用：

```pyhton
df = pd.DataFrame({'A': ['a', 'b', 'a'],
                   'B': ['c', 'c', 'b'],
                   'C': [1, 2, 3]})
df
'''
   A  B  C
0  a  c  1
1  b  c  2
2  a  b  3
'''
# 最后一列不会被处理
pd.get_dummies(df)
'''
   C  A_a  A_b  B_b  B_c
0  1    1    0    0    1
1  2    0    1    0    1
2  3    1    0    1    0
'''
```

```python
pd.get_dummies(df, columns=['A'])
'''
   B  C  A_a  A_b
0  c  1    1    0
1  c  2    0    1
2  b  3    1    0
'''
```

## 数据转置 df.T

### 理解数据转置

在数据处理分析过程中，为了充分利用行列的关系表达，我们需要对原数据的行列进行互换。转置的过程其实是沿着左上与右下形成对角线进行翻转。

![image-20230427150418170](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20230427150418170.png)

### 转置 df.T

`df.T` 属性是 `df.transpose()` 方法的别名、简写方法，今后我们只要记住 `.T` 就好啦。

```python
d1 = {'col1': [1, 2], 'col2': [3, 4]}
df1 = pd.DataFrame(data=d1)
df1
'''
   col1  col2
0     1     3
1     2     4
'''

df1_transposed = df1.T # or df1.transpose()
df1_transposed
'''
      0  1
col1  1  2
col2  3  4
'''
```

### 类型变化

如果 Dataframe 中数据类型相同，那么转置后类型不变：

```python
df1.dtypes
'''
col1    int64
col2    int64
dtype: object
'''

df1_transposed.dtypes
'''
0    int64
1    int64
dtype: object
'''
```

如果有多种类型，则为 `object`：

```python
d2 = {'name': ['Alice', 'Bob'],
      'score': [9.5, 8],
      'employed': [False, True],
      'kids': [0, 0]}
df2 = pd.DataFrame(data=d2)
df2
'''
    name  score  employed  kids
0  Alice    9.5     False     0
1    Bob    8.0      True     0
'''
df2_transposed = df2.T # or df2.transpose()
df2_transposed
'''
              0     1
name      Alice   Bob
score       9.5     8
employed  False  True
kids          0     0
'''
```

查看类型：

```python
df2.dtypes

'''name         object
score       float64
employed       bool
kids          int64
dtype: object
'''
df2_transposed.dtypes
'''
0    object
1    object
dtype: object
'''
```

### Series 转置

`Series` 也支持转置，不过它返回的是它自己，没有变化。

### 轴交换 [swapaxes](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.swapaxes.html?highlight=swapaxes#pandas.DataFrame.swapaxes)

Pandas 提供了一个 `DataFrame.swapaxes(axis1, axis2, copy=True)` 用来做轴（行列）交换。如果行列交换就相当于 `df.T`。

```python
df.swapaxes("index", "columns") # 行列交换，相当于 df.T
df.swapaxes("columns", "index") # 同上
df.swapaxes("index", "columns", copy=True) # 使生效
df.swapaxes("columns", "columns") # 无变化
df.swapaxes("index", "index") # 无变化
```

## 因子化（枚举化）值

### 基本方法 [factorize](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.factorize.html?highlight=factorize#pandas.factorize)

将一个方法进行因子化后将返回两个值，一个是因子化后的编码列表，一个是原数据的去重值列表：

```python
codes, uniques = pd.factorize(['b', 'b', 'a', 'c', 'b'])
codes
# array([0, 0, 1, 2, 0])
uniques
# array(['b', 'a', 'c'], dtype=object)
```

### 排序

使用 `sort=True` 参数后将对唯一性进行排序，编码列表将继续与原值保持对应关系，但从值的大小上将体现出顺序。

```python
codes, uniques = pd.factorize(['b', 'b', 'a', 'c', 'b'], sort=True)
codes
# array([1, 1, 0, 2, 1])
uniques
# array(['a', 'b', 'c'], dtype=object)
```

### 缺失值

缺失值不会出现在唯一值列表中，在编码中将为 -1：

```python
codes, uniques = pd.factorize(['b', None, 'a', 'c', 'b'])
codes
# array([ 0, -1,  1,  2,  0])
uniques
# array(['b', 'a', 'c'], dtype=object)
```

### 枚举类型

`Categorical` 枚举类型也可以使用此方法：

```python
cat = pd.Categorical(['a', 'a', 'c'], categories=['a', 'b', 'c'])
codes, uniques = pd.factorize(cat)
codes
# array([0, 0, 1])
uniques
# [a, c]
# Categories (3, object): [a, b, c]
```

### 应用到 Series

对 Series 操作后唯一值将生成一个 index 对象：

```python
cat = pd.Series(['a', 'a', 'c'])
codes, uniques = pd.factorize(cat)
codes
# array([0, 0, 1])
uniques
# Index(['a', 'c'], dtype='object')
```

## 爆炸序列 [explode](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.explode.html?highlight=explode)

### 基本用法

下边的两行数据中有类似列表（list-likes，包括 lists, tuples, sets, Series 和 np.ndarray）的值，我们将它们炸开后，它他乖乖回去排好了队，但是依然使用原来的索引：

```python
s = pd.Series([[1, 2, 3], 'foo', [], [3, 4]])
s
'''
0    [1, 2, 3]
1          foo
2           []
3       [3, 4]
dtype: object
'''

s.explode()
'''
0      1
0      2
0      3
1    foo
2    NaN
3      3
3      4
dtype: object
'''
```

子集行的结果 dtype 将为 object。 标量将原封不动地返回，并且空列表状将导致该行的 np.nan。 此外，爆炸集合时，输出中行的顺序将不确定。

### DataFrame 的爆炸

我们看到，对指定列进行了炸裂：

```
df = pd.DataFrame({'A': [[1, 2, 3], 'foo', [], [3, 4]], 'B': 1})
'''
df
           A  B
0  [1, 2, 3]  1
1        foo  1
2         []  1
3     [3, 4]  1
'''
df.explode('A')
'''
     A  B
0    1  1
0    2  1
0    3  1
1  foo  1
2  NaN  1
3    3  1
3    4  1
'''
```

Pandas 1.3.0 开始支持多列的炸开：

```python
df = pd.DataFrame({'A': [[0, 1, 2], 'foo', [], [3, 4]],
                   'B': 1,
                   'C': [['a', 'b', 'c'], np.nan, [], ['d', 'e']]})
df
'''
           A  B          C
0  [0, 1, 2]  1  [a, b, c]
1        foo  1        NaN
2         []  1         []
3     [3, 4]  1     [d, e]
'''
# A、C 两列执行
df.explode(list('AC'))
'''
     A  B    C
0    0  1    a
0    1  1    b
0    2  1    c
1  foo  1  NaN
2  NaN  1  NaN
3    3  1    d
3    4  1    e
'''
```

### 炸开非列表

有时候遇到不是列表的，但是具有列表的特质，我们也可以处理：

```python
df = pd.DataFrame([{'var1': 'a,b,c', 'var2': 1},
                   {'var1': 'd,e,f', 'var2': 2}])
df
'''
    var1  var2
0  a,b,c     1
1  d,e,f     2
'''
```

看看 var1 列，我们发现可以处理成列表：

```python
df.assign(var1=df.var1.str.split(',')).explode('var1')
'''
  var1  var2
0    a     1
0    b     1
0    c     1
1    d     2
1    e     2
1    f     2
'''
```

### 横向爆炸 [add_prefix](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.add_prefix.html?highlight=add_prefix#pandas.DataFrame.add_prefix)

以上的操作都是竖向爆炸，如果想横向爆炸，可以考虑使用以下方法。

```python
import pandas as pd

df = pd.DataFrame(
    dict(
        name=['A', 'B', 'C', 'D'],
        age=[10, 20, 30, 40],
        code=[['c1', 'c2'], ['c2', 'c3'], ['c1'], ['c1', 'c3']]
        )
)

df
'''
  name  age      code
0    A   10  [c1, c2]
1    B   20  [c2, c3]
2    C   30      [c1]
3    D   40  [c1, c3]
'''
```

先对列应用 pd.Series 构造为多列 DataFrame，也可以直接将此列转为列表，现用 pd.DataFrame() 构造：

```python
temp = df.code.apply(pd.Series).add_prefix('code_')
temp = pd.DataFrame(df.code.to_list()).add_prefix(f'{df.code.name}_')
temp
'''
  code_0 code_1
0     c1     c2
1     c2     c3
2     c1    NaN
3     c1     c3
'''
```

再和原数据拼接起来

```python
pd.concat([df, temp], axis=1)
'''
  name  age      code code_0 code_1
0    A   10  [c1, c2]     c1     c2
1    B   20  [c2, c3]     c2     c3
2    C   30      [c1]     c1    NaN
3    D   40  [c1, c3]     c1     c3
'''
```

如果内容不是一个原生的字典，可以考虑使用类似 `ser.str.split('_', expand=True)` 的方法，详见教程：[pandas 文本分割](https://www.gairuo.com/p/pandas-split-strings)。

## 转为 NumPy ndarray

### 概述

andas v0.24.0 引入了两种从 pandas 对象获取 NumPy 数组的新方法：

- `ds.to_numpy()`, 它可以用在 Index, Series, 和 DataFrame 对象
- `s.array`, 为 PandasArray，用在 Index 和 Series，它包装了 numpy.ndarray 接口

pandas 的 values 和 as_matrix() 不赞成使用。这两个函数旨在提高 API 的一致性，这是朝着正确方向迈出的重要一步。最后，`.values` 和 `as_matrix()` 在当前版本中不会被弃用，但预计这可能会在将来的某个时候发生，因此建议用户尽快迁移到较新的 API。

### DataFrame

`df.values` 和 `df.to_numpy()`返回的是一个 array 类型：

```python
df.values # 不建议
df.to_numpy()
'''
array([['Liver', 'E', 89, 21, 24, 64],
       ['Arry', 'C', 36, 37, 37, 57],
       ['Ack', 'A', 57, 60, 18, 84],
       ...
       ['Eli', 'E', 11, 74, 58, 91],
       ['Ben', 'E', 21, 43, 41, 74]], dtype=object)
'''
type(df.to_numpy())
# numpy.ndarray
df.to_numpy().dtype
# dtype('O')
type(df.to_numpy().dtype)
# numpy.dtype

# 指定列转
df[['name', 'Q1']].to_numpy()
```

### Series

对 Series 使用 `s.values` 和 `s.to_numpy()`返回的是一个 array 类型：

```python
df.Q1.values # 不建议
df.Q1.to_numpy()
'''
array([89, 36, 57, 93, 65, 24, 61 ...
       91, 80, 97, 60, 79, 44, 80 ...
       ...
       28, 50, 18, 10, 12, 21, 79...
       38, 43, 87, 78, 15, 15, 73...
        2, 14, 13, 96, 16, 38, 62...])
'''
type(df.Q1.to_numpy())
# numpy.ndarray
df.Q1.to_numpy().dtype
# dtype('int64')
type(df.Q1.to_numpy().dtype)
# numpy.dtype
type(df.Q1.to_numpy())
# pandas.core.arrays.numpy_.PandasArray

df.Q1.array
type(df.Q1.array)
# pandas.core.arrays.numpy_.PandasArray
```

### [to_records](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_records.html?highlight=to_records#pandas.DataFrame.to_records)

您可以使用 to_records() 方法，但是如果数据类型不是您想要的，则必须对它们进行一些处理。在下例子中，从字符串复制 df 之后，索引类型是 string（由 pandas 中的object dtype 表示）：

```python
df.to_records()
type(df.to_records())
# numpy.recarray
np.array(df.to_records())
```

### NumPy的方法

可以用 `np.array` 直接转换：

```python
np.array(df) # Dataframe 转
np.array(df.Q1) # 直接转
np.array(df.Q1.array) # PandasArray 转
np.array(df.to_records().view(type=np.matrix)) # 转为矩阵
```

