# 分组聚合

## GroupBy 基础使用

### 语法结构 [groupby](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html?highlight=groupby#pandas.DataFrame.groupby)

```pyhton
df.groupby(self, by=None, axis=0, level=None,
           as_index: bool=True, sort: bool=True,
           group_keys: bool=True,
           squeeze: bool=False,
           observed: bool=False, dropna=True)
```

其中 by 为分组字段，由于是第一个参数可以省略，可以按列表给多个。会返回一个`groupby_generic.DataFrameGroupBy`对象，如果不给定聚合方法，不会返回 DataFrame。

### 基本用法

我们可以实现类似 SQL groupby 那样的数据透视功能：

```python
df.groupby('team').sum() # 按团队分组对应列相加
df.groupby('team').mean() # 按团队分组对应列求平均
# 不同列不同的计算方法
df.groupby('team').agg({'Q1': sum,  # 总和
                        'Q2': 'count', # 总数
                        'Q3':'mean', # 平均
                        'Q4': max}) # 最大值
```

![pandasgroupby ](https://www.gairuo.com/file/pic/2020/04/pandas-df-groupby.jpg)

注：

- 如果按一列聚合，只传列名字符串，如果多个就要传由列名组成的列表
- 聚合方法可以使用 [Pandas 的数学统计函数](https://www.gairuo.com/p/pandas-statistics) 或者 Numpy 的统计函数
- 如果是 python 的内置统计函数，直接使用变量，不需要加引号
- 如果需要将空值也进行聚合，需要传入 `dropna=Flase`

以上是我们经常使用的方法。

### 多层索引分组

对多层索引数据进行分组，可以查看[多层索引数据分组](https://www.gairuo.com/p/pandas-groupby-multiIndex)内容。

### 分组对象

```python
grouped = df.groupby('team')
```

groupby 对数据分组后，会生成一个分组对象（上例中的 grouped ），分组对象非常强大，我们可以在分组对象上对数据做各种计算处理，后边我们将介绍它的操作。

## 分组对象及创建

### 数据准备

有以下动物最大速度数据：

```python
df = pd.DataFrame([('bird', 'Falconiformes', 389.0),
                   ('bird', 'Psittaciformes', 24.0),
                   ('mammal', 'Carnivora', 80.2),
                   ('mammal', 'Primates', np.nan),
                   ('mammal', 'Carnivora', 58)],
                  index=['falcon', 'parrot', 'lion',
                         'monkey', 'leopard'],
                  columns=('class', 'order', 'max_speed'))

df
'''
          class           order  max_speed
falcon     bird   Falconiformes      389.0
parrot     bird  Psittaciformes       24.0
lion     mammal       Carnivora       80.2
monkey   mammal        Primates        NaN
leopard  mammal       Carnivora       58.0
'''
```

### 创建分组对象

使用以下形式进行分组，产生分组对象：

```python
grouped = df.groupby('class') # 单个列
grouped = df.groupby('order', axis='columns') # 按行
grouped = df.groupby(['class', 'order']) # 多个
```

可以使用 `get_group()` 查看单个分组的内容：

```python
grouped.get_group('bird') # 查看鸟类分组内容
'''
       class           order  max_speed
falcon  bird   Falconiformes      389.0
parrot  bird  Psittaciformes       24.0
'''
```

关于 groupby() 的更加详细介绍可以访问 [groupby()](https://www.gairuo.com/p/pandas-groupby)。

### 分组方法

#### Python 方法

```python
# 以下使用学生成绩表数据
# 按索引奇偶行分组 True False 两组
df.groupby(lambda x:x%2==0)
# 按前后50个分组  True False 两组
df.groupby(lambda x:x>=50)
# 列名包含 Q 的分成一组
df.groupby(lambda x:'Q' in x, axis=1).sum()
```

#### 字典分组

```python
# 传入字典完成分组，键为原索引名，值为分组名
# 可实现只对部分分组
(
    df.set_index('team')
    .groupby({'A': 'A组', 'B': 'B组'})
    .sum()
)
```

#### 列计算值

```python
# 以下使用学生成绩表数据
# 按索引奇偶行分组 True False 两组
df.groupby(df.index%2==0) # 同上
# 按姓名首字母分组
df.groupby(df.name.str[0])
# 按 AB-其他团队 分组
df.groupby(df.team.isin(['A','B']))
# 按姓名第一个字母和第二个字母分组
df.groupby([df.name.str[0], df.name.str[1]])
# 按日期小时分组
df.groupby([df.time.date, df.time.hour])
```

#### 使用函数

```python
# 按日期中的年份分组
df.groupby(df.time.apply(lambda x:x.year)).count()
# 姓名首字母元音辅音分组
def get_letter_type(letter):
    if letter[0].lower() in 'aeiou':
        return 'vowel'
    else:
        return 'consonant'
# 使用函数
df.set_index('name').groupby(get_letter_type).sum()
```

#### 多种方法混合

可以将以上方法混合组成列表使用：

```python
# 使用了 python 表达式和列名
df.groupby([lambda x:x>=50, 'team']).sum()
```

#### 直接使用分组方法

可以将 `pd.DataFrame.groupby` 应用到数据中：

```python
df.pipe(pd.DataFrame.groupby, 'team').sum()
```

#### 使用分组器 Grouper

Grouper 允许指定 groupby 分组依据，功能非常强大，详见[分组器 Grouper](https://www.gairuo.com/p/pandas-grouper) 。

#### 指定索引层级

多层索引按指定索引的分组可[参阅](https://www.gairuo.com/p/pandas-groupby-multiIndex)。

### 索引

Groupby 操作后分组字段会成为索引，如果不想让它成为索引，可以使用 `as_index=False` 进行设置：

```python
df.groupby('team', as_index=False).sum()
'''
  team    Q1    Q2    Q3    Q4
0    A  1066   639   875   783
1    B   975  1218  1202  1136
2    C  1056  1194  1068  1127
3    D   860  1191  1241  1199
4    E   963  1013   881  1033
'''
```

## 分组聚合统计

### 分组统计方法

分组对象支持几乎所有的 df 的统计方法，见[数学统计方法](https://www.gairuo.com/p/pandas-statistics)，这些方法会按组统计，最终输出 df 或者序列：

```python
df.groupby('team').describe() # 描述性统计
df.groupby('team').sum() # 求和
df.groupby('team').count() # 每组数量，不包括缺失值
df.groupby('team').max() # 求最大值
df.groupby('team').min() # 求最小值
df.groupby('team').size() # 分组数量
df.groupby('team').mean() # 平均值
df.groupby('team').median() # 中位数
df.groupby('team').std() # 标准差
df.groupby('team').var() # 方差
grouped.corr() # 相关性系数
grouped.sem() # 标准误差
grouped.prod() # 乘积
grouped.cummax() # 每组的累计最大值
grouped.cumsum() # 累加
grouped.mad() # 平均绝对偏差
```

### 特殊方法

特别的有：

```python
df.groupby('team').first() # 组内第一个
df.groupby('team').last() # 组内最后一个
df.groupby('team').ngroups # 5 分组数
df.groupby('team').ngroup() # 分组序号

# 库姆计数，按组对成员标记, 支持正排倒排
# 返回每个元素在所在组的序号的序列
grouped.cumcount(ascending=False)
```

给定分位，返回每组的分位值：

```python
df = pd.DataFrame([
    ['a', 1], ['a', 2], ['a', 3],
    ['b', 1], ['b', 3], ['b', 5]
], columns=['key', 'val'])

df.groupby('key').quantile() # 0.5 分
df.groupby('key').quantile(0.33)
```

### 时序重采样 [resample](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.DataFrameGroupBy.resample.html?highlight=resample#pandas.core.groupby.DataFrameGroupBy.resample)

使用 `resample` 对时间进行分组：

```python
idx = pd.date_range('1/1/2000', periods=100, freq='T')
df = pd.DataFrame(data=1 * [range(2)],
                  index=idx,
                  columns=['a', 'b'])

# 三个周期一聚合（一分钟一个周期）
df.groupby('a').resample('3T').sum()
# 30 秒一分组
df.groupby('a').resample('30S').sum()
# 每月
df.groupby('a').resample('M').sum()
# 以右边时间点为标识
df.groupby('a').resample('3T', closed='right').sum()
```

## 分组应用函数

### 聚合 Aggregations

.aggregate()简写为.agg()。它的作用是将分组后的对象给定统计方法，也支持按字段分别给定不同的统计方法。

```python
# 所有列使用一个计算计算方法
df.groupby('team').aggregate(sum)
df.groupby('team').agg(sum)
grouped.agg(np.size)
grouped['Q1'].agg(np.mean)

## 多个计算方法
# 所有列指定多个计算方法
grouped.agg([np.sum, np.mean, np.std])
# 指定列使用多个计算方法
grouped['Q1'].agg([sum, np.mean, np.std])
# 一列使用多个计算方法
df.groupby('team').agg({'Q1': ['min', 'max'], 'Q2': 'sum'})

# 指定列名，列表是为原列和方法
df.groupby('team').Q1.agg(Mean='mean', Sum='sum')
df.groupby('team').agg(Mean=('Q1', 'mean'), Sum=('Q2', 'sum'))
df.groupby('team').agg(
    Q1_max=pd.NamedAgg(column='Q1', aggfunc='max'),
    Q2_min=pd.NamedAgg(column='Q2', aggfunc='min')
)
# 如果列名不是有效的 python 变量，则可以用以下方法
df.groupby('team').agg(**{
    '1_max':pd.NamedAgg(column='Q1', aggfunc='max')})

# 聚合结果使用函数
# lambda/函数 所有方法都可以用
def max_min(x):
    return x.max() - x.min()
# 定义函数
df.groupby('team').Q1.agg(Mean='mean',
                          Sum='sum',
                          Diff=lambda x: x.max() - x.min(),
                          Max_min=max_min
                         )

# 不同列不同的计算方法
df.groupby('team').agg({'Q1': sum,  # 总和
                        'Q2': 'count', # 总数
                        'Q3':'mean', # 平均
                        'Q4': max}) # 最大值

# 分组对象使用函数
# 定义函数
def max_min(var):
    return var.max() - var.min()
# 调用函数
df.groupby('team').agg(max_min)
```

关于 agg 可以查看 [agg 聚合操作](https://www.gairuo.com/p/pandas-agg) 详细介绍。

### 分组运算 [Transfromations](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.DataFrameGroupBy.transform.html?highlight=transform#pandas.core.groupby.DataFrameGroupBy.transform)

transform类似于agg，但不同的是它返回的是一个df，每个会将原来的值一一替换成统计后的值，比如按组计算平均值，那么返回的新的df中每个学生的成绩就是它所在的组的平均成绩。

```python
df.groupby('team').transform(max) # 最大值
df.groupby('team').transform(np.std) # 标准差
# 使用函数, 和上一个学生的差值（没有处理姓名列）
df.groupby('team').transform(lambda x: x.shift(-1))
# 函数
def score(gb):
    return (gb - gb.mean()) / gb.std()*10
# 调用
grouped.transform(score)
```

也可以用它来做按组筛选：

```python
# Q1 成绩大于60的组的所有成员
df[df.groupby('team').transform('mean').Q1 > 60]
```

如果想按组对此组的值填充一个列表值，可以用以下方法：

```python
df.groupby('a').b.transform(lambda x: [x.to_list()]*len(x))
df['a'].map(df.groupby('a')['b'].agg(list))
```

更加详细的介绍可查看教程[pandas transform 数值转换](https://www.gairuo.com/p/pandas-transform)部分。

### 筛选 [Filteration](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.DataFrameGroupBy.filter.html?highlight=filter#pandas.core.groupby.DataFrameGroupBy.filter)

 

```python
# 值的长度都大于等于 3 的
df.groupby('team').filter(lambda x: len(x) >= 3)
# Q1成绩只要有一个大于97的组
df.groupby(['team']).filter(lambda x: (x['Q1'] > 97).any())
# 所有成员平均成绩大于 60 的组
df.groupby(['team']).filter(lambda x: (x.mean() >= 60).all())
# Q1 所有成员成绩之和超过 1060 的组
df.groupby('team').filter(lambda g: g.Q1.sum() > 1060)
```

关于 filter 的详细介绍，可以查阅：[pandas filter 筛选标签](https://www.gairuo.com/p/pandas-filter)。

### 函数 Apply

对对象应用函数进行处理，以下是对所有的值乘以2:

```python
df.groupby('team').apply(lambda x: x*2)
```

实现 hive sql 中的 collect_list：

```python
df.groupby('team').apply(lambda x: x['name'].to_list())
# 输出一个 np.array
df.groupby('team').apply(np.array)
```

我们有个需求，是看每组 Q1 成绩的最高的前五个：

```python
# 各组 Q1（为参数） 成绩的前五个
def first_5(df_, c):
    return df_[c].sort_values(ascending = False).head()
# 调用函数
df.set_index('name').groupby('team').apply(first_5, 'Q1')
# group_keys 可以使分组字段不做为索引
(df.set_index('name')
 .groupby('team', group_keys=False)
 .apply(first_5, 'Q1')
)
```

可以使用 Series 来使用，索引是列表，值是统计方法。以下使用 lambda 构造一个 Series：

```python
(df.groupby('team')
  .apply(lambda x: pd.Series({
      'Q1_sum'       : x['Q1'].sum(),
      'Q1_max'       : x['Q1'].max(),
      'Q2_mean'      : x['Q2'].mean(),
      'Q4_prodsum'   : (x['Q4'] * x['Q4']).sum()
  }))
)

# 可以定义一个函数
def f_mi(x):
        d = []
        d.append(x['Q1'].sum())
        d.append(x['Q2'].max())
        d.append(x['Q3'].mean())
        d.append((x['Q4'] * x['Q4']).sum())
        return pd.Series(d, index=[['Q1', 'Q2', 'Q3', 'Q4'], 
                                   ['sum', 'max', 'mean', 'prodsum']])
# 使用函数
df.groupby('team').apply(f_mi)
'''
          Q1    Q2         Q3       Q4
         sum   max       mean  prodsum
team
A     1066.0  87.0  51.470588  51129.0
B      975.0  99.0  54.636364  76696.0
C     1056.0  96.0  48.545455  68571.0
D      860.0  97.0  65.315789  87473.0
E      963.0  98.0  44.050000  71317.0
'''
```

不过以上建议在复杂的需求场景下使用。一行代码可以按分组导出 Excel 文件：

```python
# 一个分组导出一个 Excel 文件
(
    df.groupby('team')
    .apply(lambda x: x.to_excel(f'{x.name}.xlsx'))
)
```

要注意的是，name 是分组名，不是 name 列，要取同名列的话可以使用切片 `x['name']`。可以查看此案例 [pandas 按分组一个分组导出一个文件](https://www.gairuo.com/m/pandas-exports-file-group) 。

关于 apply 的详细介绍，可以查阅：[pandas apply 函数应用](https://www.gairuo.com/p/pandas-apply)。

### 管道方法

类似于 df 的管道方法，分组对象的管道方法是接收之前的分组对象将同组里的所有数据应用在方法中。

```python
# 最大值和最小值之间的差值
df.groupby('team').pipe(lambda x: x.max() - x.min())

# 使用函数
def mean_diff(x):
    return x.get_group('A').mean() - x.get_group('B').mean()
# 以上定义了 A 组和 B 组平均值的差值
df.groupby('team').pipe(mean_diff)
```

关于 pipe 的详细介绍，可以查阅：[pandas pipe 管道方法](https://www.gairuo.com/p/pandas-pipe)。

DataFrame、Series、GroupBy 等使用 pipe 时的语法相同，以下以 DataFrame 为例：

```python
DataFrame.pipe(
    func: 'Callable[..., T] | tuple[Callable[..., T], str]',
    *args,
    **kwargs,
) -> 'T'
```

参数：

- func：函数，应用于系列/数据帧的函数。args 和 kwargs 被传递到 func。或者是一个（callable，data_keyword）元组，其中 data_keyword 是一个字符串，表示需要Series/DataFrame 的 callable 关键字
- args：可迭代对象, 可选，函数的位置参数
- kwargs：mapping, 可选，传入 func 的关键字参数字典

返回：

- object：func 处理后的任意数据类型

相当于执行 `func(self, *args, **kwargs)`，self 则是原数据。其中函数可以用以下几种形式表示：

```python
df.pipe(fun) # 自定义
df.pipe(max) # python 内置函数
df.pipe(lambda x: x*2) # lambda
df.pipe(np.mean) # numpy 等其他库的函数 ufunc
df.pipe(pd.Series.mean) # Pandas 自己的函数
```



使用 `.pipe` 将需要 Series、DataFrames 或 GroupBy 对象的函数链接在一起。而不是写作：

```
func(g(h(df), arg1=a), arg2=b, arg3=c)
```

而写做以下链式调用的形式（也叫链式方法），可以清晰地看到每一步对数据做了什么操作：

```python
(
    df.pipe(h)
    .pipe(g, arg1=a)
    .pipe(func, arg2=b, arg3=c)
)
```

如果有一个函数将数据作为第二个参数，则传递一个元组，指示哪个关键字需要数据。例如，假设 f 的数据为 arg2：

```python
(
    df.pipe(h)
    .pipe(g, arg1=a)
    .pipe((func, 'arg2'), arg1=a, arg3=c)
)
```

## 分组对象的操作

### 选择

有了 GroupBy 对象，可能希望对每个列进行不同的操作，使用类似于 `[]` 从 DataFrame 获取列：

```python
grouped = df.groupby(['team'])
grouped_C = grouped['C']
grouped_D = grouped['D']
```

也可以先选择列，再进行分组，返回一个序列分组对象：

```python
df['Q1'].groupby(df['team'])
# SeriesGroupBy
```

### 分组

```python
df.groupby('team').groups # 显示所有分组
grouped.get_group('A') # 选择指定分组

# 多层索引的选择
grouped2 = df.groupby(['team', 'Q1'])
grouped2.get_group(('A', 57))
```

### 迭代分组

以下将迭代出分组名和分组内容：

```python
for name, group in grouped:
    print(name)
    print(group)
```

### 分组排序

分组后会按分组字段进行排序（见上例索引示例），如果不想这样排序可以`sort=False`则会按内容首次出现的顺序显示：

```python
df.groupby('team', sort=False, as_index=False).sum()
'''
  team    Q1    Q2    Q3    Q4
0    E   963  1013   881  1033
1    C  1056  1194  1068  1127
2    A  1066   639   875   783
3    D   860  1191  1241  1199
4    B   975  1218  1202  1136
'''
```

### 基本操作

```python
# 以下部分需要聚合统计方法才能显示结果
# 选择列 返回一个SeriesGroupBy
df.groupby('team')['Q1']
df.groupby('team').all()
df.groupby('team').any()
grouped.backfill()
grouped.bfill()
df.groupby('team').head() # 每组显示前5个
grouped.tail(1) # 每组最后一个
grouped.rank() # 排序值
grouped.fillna(0)
grouped.indices # 字典 {分组名 -> 索引}.

# 分组中的第几个值，分组子集查询
gp.nth(1) # 第一个
gp.nth(-1) # 最后一个
gp.nth([-2, -1])
# 第 n 个非空项
gp.nth(0, dropna='all')
gp.nth(0, dropna='any')
# 可使用切片 1.4+ 版本
gp.nth[1:-1] # 选择指定行
gp.nth[1, -1] # 指定行列索引
gp.nth[:1, -1:] # 开区间
gp.nth(slice(1, -1)) # 内置函数写法
gp.nth([slice(None, 1), slice(-1, None)])

df.groupby('team').shift(-1) # 组内移动
grouped.tshift(1) # 按时间周期移动

df.groupby('team').any()
df.groupby('team').all()

df.groupby('team').rank() # 在组内的排名


# 仅 SeriesGroupBy 可用
# 每组最大的两个
df.groupby("team").Q1.nlargest(2)
df.groupby("team").Q1.nsmallest(2)
df.groupby("team").Q1.nunique() # 每组去重数量
df.groupby("team").Q1.unique() #  每组去重值
df.groupby("team").Q1.value_counts() #  每组去重值及数量
df.groupby("team").Q1.is_monotonic_increasing # 每组值是否单调递增
df.groupby("team").Q1.is_monotonic_decreasing # 每组值是否单调递减


# 仅 DataFrameGroupBy 可用
df.groupby("team").corrwith(df2) # 相关性
```

### 可视化

```python
gp.plot() # 各组的折线图
gp.plot.bar() #
df.groupby('team').hist() # 直方图
df.groupby('team').boxplot() # 箱线图
df.boxplot(by="team") # 同上
```

### unstack

[参见](https://www.gairuo.com/p/pandas-stacking)

### T

[参见](https://www.gairuo.com/p/pandas-transpose)

## 分组器

### 基本结构

```python
pandas.Grouper(key=None, level=None, freq=None, axis=0, sort=False)

# df.groupby('team')
df.groupby(pd.Grouper('team')).sum()
# 如果是时间，可以60秒一分组
df.groupby(Grouper(key='date', freq='60s'))
# 轴方向
df.groupby(Grouper(level='date', freq='60s', axis=1))
# 按索引
df.groupby(pd.Grouper(level=1)).sum()
```

### 按列分组

单个列：

```python
df.groupby(pd.Grouper('team'))
```

多个列：

```python
df.groupby([pd.Grouper(freq='1M', key='Date'), 'Buyer']).sum()
df.groupby([pd.Grouper('dt', freq='D'),
            pd.Grouper('other_column')
           ])
```

### 按轴

```python
df.groupby([pd.Grouper(level='second'), 'A']).sum()
df.groupby([pd.Grouper(level=1), 'A']).sum()
```

### 时序周期

按时间周期分组，需要使用时间字段，如果不是日期时间类型需要进行类型转换：

```python
df['column_name'] = pd.to_datetime(df['column_name'])
df.groupby(pd.Grouper(key='column_name', freq="M")).mean()
```

可以自定义时间周期：

```python
# 10 年一个周期
df.groupby(pd.cut(df.date,
                  pd.date_range('1970', '2020', freq='10YS'),
                  right=False)
          ).mean()
```

## 数据分箱 [cut](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html?highlight=cut#pandas.cut) | [qcut](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.qcut.html?highlight=qcut#pandas.qcut)

数据分箱（Data binning，也称为离散组合或数据分桶）是一种数据预处理技术，将原始数据分成小区间，即一个 bin（小箱子），它是一种量子化的形式。

Pandas 实现连续数据的离散化处理主要基于两个函数：

- `pandas.cut` 根据指定分界点对连续数据进行分箱处理
- `pandas.qcut` 根据指定箱子的数量对连续数据进行等宽分箱处理

注：所谓等宽指的是每个箱子中的数据量是相同的。

### pd.cut 

`pd.cut` 可以指定区间将数字进行划分，以下三个值将数据划分成两个区间（及格或者不及格）：

```python
pd.cut(df.Q1, bins=[0, 60, 100])
'''
0     (60, 100]
1       (0, 60]
        ...
98      (0, 60]
99      (0, 60]
Name: Q1, Length: 100, dtype: category
Categories (2, interval[int64]): [(0, 60] < (60, 100]]
'''
```

应用到分组中：

```python
df.Q1.groupby(pd.cut(df.Q1, bins=[0, 60, 100])).count()
'''
Q1
(0, 60]      57
(60, 100]    43
Name: Q1, dtype: int64
'''
df.groupby(pd.cut(df.Q1, bins=[0, 60, 100])).count()
```

按区间做映射的例子：

```python
df = pd.DataFrame({'A':[1, 3, 5, 7, 9]})
df.assign(B=pd.cut(df.A, [0,5,7, float('inf')], 
                   labels=['差','中','好'])
         )
'''
   A  B
0  1  差
1  3  差
2  5  差
3  7  中
4  9  好
'''
```

其他参数：

```python
# 不用区间，使用数字做为标签（0，1，2，n）
pd.cut(df.Q1, bins=[0, 60, 100],labels=False)
# 指定标签名
pd.cut(df.Q1, bins=[0, 60, 100],labels=['不及格','及格',])
# 包含最低部分
pd.cut(df.Q1, bins=[0, 60, 100], include_lowest=True)
# 是否包含右边，闭区间，下例 [89, 100)
pd.cut(df.Q1, bins=[0, 89, 100], right=False)
```



### pd.qcut

pd.qcut 指定所分箱子的数量，pandas 会自动进行分箱：

```python
pd.qcut(df.Q1,q=2)
'''
0      (51.5, 98.0]
1     (0.999, 51.5]
          ...
98    (0.999, 51.5]
99    (0.999, 51.5]
Name: Q1, Length: 100, dtype: category
Categories (2, interval[float64]): [(0.999, 51.5] < (51.5, 98.0]]
'''
```

应用到分组中：

```python
df.Q1.groupby(pd.qcut(df.Q1,q=2)).count()
'''
Q1
(0.999, 51.5]    50
(51.5, 98.0]     50
Name: Q1, dtype: int64
'''
df.groupby(pd.qcut(df.Q1,q=2)).max()
```

其他参数：

```python
pd.qcut(range(5), 4)
pd.qcut(range(5), 4, labels=False)
# 指定标签名
pd.qcut(range(5), 3, labels=["good", "medium", "bad"])
# 返回箱子标签 array([ 1. , 51.5, 98. ]))
pd.qcut(df.Q1,q=2, retbins=True)
# 分箱位小数位数
pd.qcut(df.Q1,q=2,precision=3)
# 排名分3个层次
pd.qcut(df.Q1.rank(method='first'),3)
```

