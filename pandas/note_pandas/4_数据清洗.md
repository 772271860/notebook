# 数据清洗

## 数据清洗操作

数据清洗或数据清理是从记录集、表或数据库中检测和纠正损坏或记录不准确的数据的过程。识别数据中不完整、不正确、不准确或不相关的部分，然后替换、修改或删除脏的或粗糙的数据。

### 主要内容

数据清洗是通过删除或修改不正确、不完整、不相关、重复或格式不正确的数据来为数据分析做准备的过程。

当涉及到分析数据时，这些数据通常是不必要的或没有帮助的，因为它可能会阻碍分析过程或导致不准确的结果。有几种方法可以清理数据，具体取决于数据的存储方式以及数据分析的方向。

数据清理不是简单地擦除信息以为新数据腾出空间，而是找到一种在不必删除信息的情况下最大限度地提高数据集准确性的方法。

首先，数据清理包括删除数据，也包括修复拼写和语法错误、标准化数据集、纠正相关错误（如空字段、缺少代码和识别重复数据点）。数据清理被认为是数据科学基础的一个基本要素，因为它在分析过程和发现可靠答案中起着重要作用。

最重要的是，数据清理的目标是创建标准化和统一的数据集，以允许商业智能和数据分析工具轻松访问和查找正确的数据。

### 主要操作

Pandas 提供以下核心的数据清洗操作：

- DataFrame.dropna(self[, axis, how, thresh, …])
- DataFrame.fillna(self[, value, method, …])
- DataFrame.replace(self[, to_replace, value, …])
- DataFrame.interpolate(self[, method, axis, …])

主要完成以下工作：

- 缺失值的认定
- 缺失值数字
- 缺失日期时间
- 插入缺失值
- 缺失值计算
- 聚合分组中的缺失值
- 缺失值填充 .interpolate()
- 清除缺失值
- 替换泛型值

接下来，请继续查看教程，看看 Pandas 在这方面是怎么做的吧。



## 缺失值判定

### 缺失值的类型

一般使用特殊类型 `NaN` 代表缺失值，可以用 Numpy 可定义它`np.NaN/np.nan`。在 Pandas 1.0 以后实验性地使用一个标量 `pd.NA` 来代表。

如果想把正负无穷也为认是缺失值，可以通过以下全局配置来设定：

```python
pandas.options.mode.use_inf_as_na = True
```

以下数据 NaN 为缺失值：

```python
(pd.DataFrame(np.random.randn(5, 3),
              index=['a', 'c', 'e', 'f', 'h'], 
              columns=['one', 'two', 'three'])
.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])
)
'''
        one       two     three
a  1.632088 -0.062136 -1.389717
b       NaN       NaN       NaN
c  0.151073  1.145583 -1.893389
d       NaN       NaN       NaN
e -0.313452 -0.029717 -0.104649
f -0.128399  1.478465 -1.215389
g       NaN       NaN       NaN
h -1.504212 -0.409655 -1.263877
'''
```

### 缺失值的判断 [notna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.notna.html?highlight=notna#pandas.DataFrame.notna)

可以判断是否缺失值，DataFrame 和 Series 一般都支持。：

```python
# 不是缺失值
df.one.notna()
'''
a     True
b    False
c     True
d    False
e     True
f     True
g    False
h     True
Name: one, dtype: bool
'''
# 是缺失值
df.isna()
# 进行筛选
df[df.one.notna()]
```

需要注意的是，Numpy 中 np.nan 和 np.nan 不相等，因此不能用 `==/!=` 进行对比：

```python
None == None  # noqa: E711
# True
 np.nan == np.nan
# False
None == np.nan
# False
```

因此，请使用：

```python
df.notna()
df['team'].isna()
df['team'].isnull()
```

### 缺失值查询 [isna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isna.html?highlight=isna#pandas.DataFrame.isna) | [isnull](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isnull.html?highlight=isnull#pandas.DataFrame.isnull)

```python
# 每列有多少个缺失值
df.isnull().sum()
# 每行有多少个缺失值
df.isnull().sum(1)
# 总共共有多少个缺失值
df.isna().sum().sum()
# 有缺失值的行
df.loc[df.isna().any(1)]
# 有缺失值的列
df.loc[:,df.isna().any()]
# 没有缺失值的行
df.loc[~(df.isna().any(1))]
# 没有缺失值的列
df.loc[:,~(df.isna().any())]

# 返回第一个非NA/空值的索引
df.first_valid_index() # 0
# 返回最后一个非NA/空值的索引
df.last_valid_index() # 99
```

### 整型中的缺失值

由于 NaN 是浮点型，因此一列甚至缺少一个整数的整数列都将转换为浮点。

```python
pd.Series([1, 2, np.nan, 4], dtype=pd.Int64Dtype())
'''
0       1
1       2
2    <NA>
3       4
dtype: Int64
'''
```

### 时间中的缺失值

对于时间中的缺失值，Pandas 提供了一个 `NaT` 来表示，并且 NaT 和 NaN 之间是兼容的：

```python
df['timestamp'] = pd.Timestamp('20120101')
df.loc[['a', 'c', 'h'], ['one', 'timestamp']] = np.nan
df.timestamp
'''
a          NaT
b   2012-01-01
c          NaT
d   2012-01-01
e   2012-01-01
f   2012-01-01
g   2012-01-01
h          NaT
Name: timestamp, dtype: datetime64[ns]
'''
```

### 插入缺失值

可以使用 `None` 等方法将内容修改为缺失值：

```python
s.loc[0] = None
s.loc[1] = np.nan
df.two = pd.NA
```

## 缺失值参与计算

### 矩阵加法

以下是两个包含缺失值的数据之间的加法运算：

```python
a
'''
        one       two
a       NaN -0.282863
c       NaN  1.212112
e  0.119209 -1.044236
f -2.104569 -0.494929
h -2.104569 -0.706771
'''

b
'''
        one       two     three
a       NaN -0.282863 -1.509059
c       NaN  1.212112 -0.173215
e  0.119209 -1.044236 -0.861849
f -2.104569 -0.494929  1.071804
h       NaN -0.706771 -1.039575
'''

a + b
'''
        one  three       two
a       NaN    NaN -0.565727
c       NaN    NaN  2.424224
e  0.238417    NaN -2.088472
f -4.209138    NaN -0.989859
h       NaN    NaN -1.413542
'''
```

### 求和逻辑

计算逻辑如下：

- 如果使用 sum() 缺失值会被认为是0

- cumsum() 和 cumprod() 将忽略 NA 值， 但值会保留在序列中，可以使用skipna=False跳过。

- 

- ```python
  df
  '''
          one       two     three
  a       NaN -0.282863 -1.509059
  c       NaN  1.212112 -0.173215
  e  0.119209 -1.044236 -0.861849
  f -2.104569 -0.494929  1.071804
  h       NaN -0.706771 -1.039575
  '''
  
  df['one'].sum()
  # -1.9853605075978744
  
  df.mean(1)
  '''
  a   -0.895961
  c    0.519449
  e   -0.595625
  f   -0.509232
  h   -0.873173
  dtype: float64
  '''
  
  df.cumsum()
  '''
          one       two     three
  a       NaN -0.282863 -1.509059
  c       NaN  0.929249 -1.682273
  e  0.119209 -0.114987 -2.544122
  f -1.985361 -0.609917 -1.472318
  h       NaN -1.316688 -2.511893
  '''
  
  df.cumsum(skipna=False)
  '''
     one       two     three
  a  NaN -0.282863 -1.509059
  c  NaN  0.929249 -1.682273
  e  NaN -0.114987 -2.544122
  f  NaN -0.609917 -1.472318
  h  NaN -1.316688 -2.511893
  '''
  pd.Series([np.nan]).sum()
  # 0.0
  pd.Series([], dtype="float64").sum()
  #  0.0
  pd.Series([np.nan]).prod()
  # 1.0
  pd.Series([], dtype="float64").prod()
  # 1.0
  ```

### 聚合

如果聚合分组的列里有空值，则会自动忽略这些值（就当它不存在）：

```python
df
'''
        one       two     three
a       NaN -0.282863 -1.509059
c       NaN  1.212112 -0.173215
e  0.119209 -1.044236 -0.861849
f -2.104569 -0.494929  1.071804
h       NaN -0.706771 -1.039575
'''

df.groupby('one').mean()
'''
                two     three
one
-2.104569 -0.494929  1.071804
 0.119209 -1.044236 -0.861849
'''
```

### 其他

.count() 缺失值不计数

## 缺失值填充

### 填写值 [fillna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html?highlight=fillna#pandas.DataFrame.fillna)

`fillna(x)` 可以将缺失值填充指定的值。以下为几种常见的填充方法：

```python
df = pd.DataFrame([[np.nan, 2, np.nan, 0],
                   [3, 4, np.nan, 1],
                   [np.nan, np.nan, np.nan, 5],
                   [np.nan, 3, np.nan, 4]],
                  columns=list('ABCD'))
# 填充为 0
df.fillna(0)
# 填充为指定字符
df.fillna('missing')
df.fillna('暂无')
df.fillna('待补充')
# 指定字段填充
df.one.fillna('暂无')
# 使填充内容生效
df.one.fillna(0, inplace=True)
# 只替换第一个
df.fillna(0, limit=1)
# 不同列替换不同的值
values = {'A': 0, 'B': 1, 'C': 2, 'D': 3}
df.fillna(value=values)
```

注意：以上填写不会马上生效，需要重新赋值给 df 或者 `inplace=True`。

### 填写方式

不指定值，使用一定的方法。

```python
# 使用 method{‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default None
# 使用上一个有效值填充
df.fillna(method='backfill')
# 同 backfill
df.fillna(method='bfill')
# 把当前值广播到后边的缺失值
df.fillna(method='pad')
# 同 pad
df.fillna(method='ffill')
```

### 别名

总结如下：

- pad / ffill：向前填充
- bfill / backfill：向后填充

fillna(method='ffill') 可以简写为 `ffill()` ， fillna(method='bfill') 可以简写为 `bfill()`

### 填充计算值

填充方法：

```python
# 填充列的平均值
df.fillna(df.mean())
# 对指定列填充平均值
df.fillna(df.mean()['B':'C'])
# 填充列的平均值，另外一个方法
df.where(pd.notna(df), df.mean(), axis='columns')
```

特别的计算：

```python
# 第一个非空值
df.fillna(method='bfill').head(1).iloc[0]

# 第一个非空值索引
df.notna().idxmax()
df.apply(pd.Series.first_valid_index)
```

### 数据替换 [replace](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html?highlight=replace#pandas.DataFrame.replace)

缺失值填充的另外一个思路是使用替换方法 `df.replace`。

```python
# 将指定列的空值替换成指定值
df.replace({'toy': {np.nan: 100}})
```

## 缺失值删除

### 数据准备

一般删除会针对行进行，如一行中有缺失值就会删除，当然也会有针对列的。

```python
df = pd.DataFrame({"name": ['Alfred', 'Batman', 'Catwoman'],
                   "toy": [np.nan, 'Batmobile', 'Bullwhip'],
                   "born": [pd.NaT, pd.Timestamp("1940-04-25"),
                            pd.NaT]})

'''
       name        toy       born
0    Alfred        NaN        NaT
1    Batman  Batmobile 1940-04-25
2  Catwoman   Bullwhip        NaT
'''
```

### 缺失值删除 [dropna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html?highlight=dropna#pandas.DataFrame.dropna)

下是一些常见操作：

```python
# 删除所有有缺失值的行
df.dropna()
# 删除所有有缺失值的列
df.dropna(axis='columns')
df.dropna(axis=1)
# 删除所有值缺失的行
df.dropna(how='all')
# 不足2个非空值时删除
df.dropna(thresh=2)
# 指定判断缺失值的列范围
df.dropna(subset=['name', 'born'])
# 使删除和的结果生效
df.dropna(inplace=True)
# 指定列的缺失值删除
df.toy.dropna()
```

## 插值填充

### 插值法

插值就是在已知数据之间计算估计值的过程，是一种实用的数值方法，是函数逼近的重要方法。在信号处理和图形分析中，插值运算的应用较为广泛。

插值是离散函数逼近的重要方法，利用它可通过函数在有限个点处的取值状况，估算出函数在其他点处的近似值。

插值法是根据已知数据点来预测未知数据点，假如你有n个已知条件，就可以求一个n-1次的插值函数P（x），使得P（x）接近未知原函数f（x），并由插值函数预测出你需要的未知点值。而有n个条件求n-1次P（x）的过程，实际上就是求n元一次线性方程组。

### 插值方式 [interpolate](https://pandas.pydata.org/docs/user_guide/missing_data.html#interpolation)

以下是一个非常简单的示例，其中一个值是缺失的，我们对它进行差值：

```python
s = pd.Series([0, 1, np.nan, 3])
s.interpolate()
'''
0    0.0
1    1.0
2    2.0
3    3.0
dtype: float64
'''
```

默认`linear` 方法，会认为是一条直线。

### 计算方法

默认 method=‘linear’ 如果你的数据增长速率越来越快，可以选择 method='quadratic' 二次插值。如果数据集呈现出累计分布的样子，推荐选择 method='pchip'。如果需要填补缺省值，以平滑绘图为目标，推荐选择 method='akima'。method='akima' 和 method = ‘pchip’，需要你的环境中安装了 Scipy 库。除此之外，method='barycentric' 和 method='pchip' 同样也需要 Scipy 才能使用。



使用插值方法，可为：

- linear：线性，忽略索引，并将值等距地对待，这是MultiIndexes支持的唯一方法
- time：时间，以插值给定的时间间隔长度处理每日或更高粒度的数据
- index, values：索引，值，使用索引的实际数值
- pad：使用现有值填写NaN。
- ‘nearest’, ‘zero’, ‘slinear’, ‘quadratic’, ‘cubic’, ‘spline’, ‘barycentric’, ‘polynomial’：传递给 scipy.interpolate.interp1d，这些方法使用索引的数值。 ‘polynomial’ 和 ‘spline’ 都要求您还指定一个顺序(int)，例如 df.interpolate(method='polynomial'，order=5)
  - nearest：最近
  - zero：零
  - slinear：线性
  - quadratic：二次方
  - cubic：立方
  - spline：花键，样条插值
  - barycentric：重心插值
  - polynomial：多项式
- ‘krogh’, ‘piecewise_polynomial’, ‘spline’, ‘pchip’, ‘akima’: SciPy 类似名称的插值方法。
  - krogh: 克罗格插值
  - piecewise_polynomial: 分段多项式
  - spline: 样条插值
  - pchip: 立方插值
  - akima: 阿克玛插值
- from_derivatives：指 scipy.interpolate.BPoly.from_derivatives，它替换了 scipy 0.18 中的 piecewise_polynomial 插值方法。

### 其他参数

- axis: 插值应用的轴方向，可选择 {0 or ‘index’, 1 or ‘columns’, None}, 默认为 None
- limitint: 要填充的连续 NaN 的最大数量， 必须大于 0。
- inplace: 是否将最终结果替换原数据，默认为 False
- limit_direction: 限制方向，可传入 {‘forward’, ‘backward’, ‘both’}, 默认 ‘forward’，如果指定了限制，则将沿该方向填充连续的 NaN
- limit_area: 限制区域，可传入 {None, ‘inside’, ‘outside’}, 默认 None，如果指定了限制，则连续的NaN将被此限制填充
  - None: 没有填充限制
  - ‘inside’: 仅填充有效值包围的NaN（内插）
  - ‘outside’: 仅将NaN填充到有效值之外（外推）
- downcast: 可传入‘infer’ 或者 None, 默认是 None，如果可以向下转换 dtypes
- **kwargs: 传递给插值函数的关键字参数

可参见官网的 [interpolation user_guide](https://pandas.pydata.org/docs/user_guide/missing_data.html#interpolation)

### 常用插值方法

常用的有以下几种方法：

（1）邻近点插值（method=’nearest’）。

（2）线性插值（method=’linear’）：在两个数据点之间连接直线，计算给定的插值点在直线上的值作为插值结果，该方法是interp1函数的默认方法。

（3）三次样条插值（method=’spline’）：通过数据点拟合出三次样条曲线，计算给定的插值点在曲线上的值作为插值结果。

（4）立方插值（method=’pchip’or’cubic’）：通过分段立方Hermite插值方法计算插值结果。

### 常见特点

选择一种插值方法时，考虑的因素包括运算时间、占用计算机内存和插值的光滑程度。一般来说：

- 邻近点插值方法的速度最快，但平滑性最差；
- 线性插值方法占用的内存较邻近点插值方法多，运算时间也稍长，与邻近点插值不同，其结果是连续的，但顶点处的斜率会改变；
- 三次样条插值方法的运算时间最长，但内存的占用较立方插值法要少，但其插值数据和导数都是连续的。在这4种方法中，三次样条插值结果的平滑性最好，但如果输入数据不一致或数据点过近，就可能出现很差的插值效果。

## 数据替换

### 指定值替换

以下是在 Series 中将 0 替换为 5：

```python
ser = pd.Series([0., 1., 2., 3., 4.])
ser.replace(0, 5)
```

也可以批量替换：

```python
# 一一对应进行替换
ser.replace([0, 1, 2, 3, 4], [4, 3, 2, 1, 0])
# 用字典映射对应替换值
ser.replace({0: 10, 1: 100})
# 将 a 列的 0 b 列中的 5 替换为 100
df.replace({'a': 0, 'b': 5}, 100)
#  指定列里的替换规划
df.replace({'a': {0: 100, 4: 400}})
```

### 使用替换方式

除了给定指定值进行替换，我们还可以指定一些替换的方法：

```python
# 将 1，2，3 替换为它们前一个值
ser.replace([1, 2, 3], method='pad') # ffill 是它同义词
# 将 1，2，3 替换为它们后一个值
ser.replace([1, 2, 3], method='bfill')
```

如果指定的要替换的值不存在，则不起作用，也不会报错。以上的替换也适用了字符类型数据。

### 字符替换

如果遇到字符比较复杂的内容，就是使用正则（默认没有开启）进行匹配：

```python
# 把 bat 替换为 new
df.replace(to_replace='bat', value='new')
# 利用正则将 ba 开头的替换为 new
df.replace(to_replace=r'^ba.$', value='new', regex=True)
# 如果多列规则不一的情况下可以按以下格式对应传入
df.replace({'A': r'^ba.$'}, {'A': 'new'}, regex=True)
# 多个规则替换为同一个值
df.replace(regex=[r'^ba.$', 'foo'], value='new')
# 直接多个正则及对应的替换内容
df.replace(regex={r'^ba.$': 'new', 'foo': 'xyz'})
```

### 缺失值相关替换

替换可以处理缺失值相关的问题，如我们可以将无效的值先替换为 nan，再做缺失值处理：

```python
d = {'a': list(range(4)),
     'b': list('ab..'),
     'c': ['a', 'b', np.nan, 'd']
    }
df = pd.DataFrame(d)
# 将.替换为 nan
df.replace('.', np.nan)
# 使用正则，将空格等替换为 nan
df.replace(r'\s*\.\s*', np.nan, regex=True)
# 对应替换，a 换 b, 点换 nan
df.replace(['a', '.'], ['b', np.nan])
# 点换 dot, a 换 astuff(第一位+)
df.replace([r'\.', r'(a)'], ['dot', r'\1stuff'], regex=True)
# b 中的点要替换，替换为 b 替换规则为 nan，可以多列
df.replace({'b': '.'}, {'b': np.nan})
# 使用正则
df.replace({'b': r'\s*\.\s*'}, {'b': np.nan}, regex=True)
# b列的 b 值换为空
df.replace({'b': {'b': r''}}, regex=True)
# b 列的点空格等换 nan
df.replace(regex={'b': {r'\s*\.\s*': np.nan}})
# b列点等+ty
df.replace({'b': r'\s*(\.)\s*'},
           {'b': r'\1ty'},
           regex=True)
# 多个正则规则
df.replace([r'\s*\.\s*', r'a|b'], np.nan, regex=True)
# 用参数名传参
df.replace(regex=[r'\s*\.\s*', r'a|b'], value=np.nan)
```

替换为 None:

```python
s = pd.Series([10, 'a', 'a', 'b', 'a'])
# 将 a 换为 none
s.replace({'a': None})
# 会使用前一个值，前两个为 10，最后一个为 b method='pad'
s.replace('a', None)

# 如果 nan 替换不成功
df.replace(np.nan, None)
# 可以用以下替换
df.where(df.notnull(), None)
```

### 数字替换

```python
# 造数据
df = pd.DataFrame(np.random.randn(10, 2))
df[np.random.rand(df.shape[0]) > 0.5] = 1.5
# 将 1.5 替换为 nan
df.replace(1.5, np.nan)
# 将1.5换为 nan,等于左上角的值换为 a
df.replace([1.5, df.iloc[0, 0]], [np.nan, 'a'])
# 使替换生效
df.replace(1.5, np.nan, inplace=True)
```

### 修剪 [clip](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.clip.html?highlight=clip#pandas.DataFrame.clip)

对一些极端值，如过大或者过小，可以使用 df.clip(lower, upper) 来修剪，当数据大于 upper 时，使用 upper 的值，小于 lower 时用 lower 的值，就像 numpy.clip 方法一样。

```python
df = pd.DataFrame({'a': [-1, 2, 5], 'b': [6, 1, -3]})
df
'''
   a  b
0 -1  6
1  2  1
2  5 -3
'''

# 修剪成最大为3最小为0
df.clip(0,3)
'''
   a  b
0  0  3
1  2  1
2  3  0
'''

# 使用每个列元素的特定下限和上限阈值进行剪辑
# 列，不能小于对应 c 位置的值，不能大于对应的+1值
c = pd.Series([-1, 1, 3])
df.clip(c, c+1, axis=0)
'''
   a  b
0 -1  0
1  2  1
2  4  3
'''
```

## 缺失值 NA 标量

### 类型

它的类型检测：

```python
s = pd.Series([1, 2, None], dtype="Int64")
'''
0       1
1       2
2    <NA>
dtype: Int64
'''
s[2]
# <NA>
s[2] is pd.NA
# True
```

它是一个缺失值无疑：

```python
pd.isna(pd.NA)
# True
```

当前（1.0.3版本），pandas 默认尚未使用 NA 数据类型（在创建 DataFrame 或 Series时，或在读取数据时），因此您需要显式指定 dtype。 `df.convert_dtypes()` 就是一个非常好用的办法。

### 算术运算

它各种运算结果还是 ，但也有一些特殊情况：

```python
# 加法
pd.NA + 1
# <NA>
# 乘法
'a' * pd.NA
# <NA>
pd.NA ** 0
# 1
1 ** pd.NA
# 1
```

一些比较运算：

```python
pd.NA == 1
# <NA>
pd.NA == pd.NA
# <NA>
pd.NA < 2.5
# <NA>
```

### 逻辑操作

对于逻辑运算，pd.NA遵循三值逻辑（或Kleene逻辑，类似于R，SQL和Julia）的规则。 此逻辑意味着仅在逻辑上需要时才传播缺失值。

例如，对于逻辑“或”运算（|），如果其中一个操作数为True，则我们已经知道结果将为True，而与其他值无关（因此无论缺失值是True还是False）。 在这种情况下，pd.NA不会传播：

或：

```python
# True：
True | False
# True
True | pd.NA
# True
pd.NA | True
# True

# False：
False | True
# True
False | False
# False
False | pd.NA
# <NA>
```

与：

```python
False & True
# False
False & False
# False
False & pd.NA
# False
True & True
# True
True & False
# False
True & pd.NA
# <NA>
```

### 在布尔类型中

由于 NA 的实际值是未知的，因此将NA转换为布尔值会引发错误。这样在 if 条件中无法直接做逻辑判断，可以使用 pd.isna(pd.NA) 来判断。当然，预先做好填充值是最好的。

### Numpy 函数中使用

大多数情况下会返回 `<NA>` ，如：

```python
np.log(pd.NA)
# <NA>
np.add(pd.NA, 1)
# <NA>
```

## 重复值

### 重复值的识别 [duplicated](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.duplicated.html?highlight=duplicated#pandas.DataFrame.duplicated)

`df.duplicated(subset=None, keep='first')`可以返回表示重复行的布尔系列，可以指定列。keep参数确定要标记的重复项（如果有），选项有：

- first：将除第一次出现的重复值标记为True，默认。
- last：将除最后一次出现的重复值标记为True。
- False：将所有重复值标记为True。

来实际操作一下：

```python
df = pd.DataFrame({
    'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],
    'style': ['cup', 'cup', 'cup', 'pack', 'pack'],
    'rating': [4, 4, 3.5, 15, 5]
})
df
'''
    brand style  rating
0  Yum Yum   cup     4.0
1  Yum Yum   cup     4.0
2  Indomie   cup     3.5
3  Indomie  pack    15.0
4  Indomie  pack     5.0
'''
```

默认情况下，对于每组重复的值，第一次出现都设置为False，所有其他值设置为True。

```python
df.duplicated()
'''
0    False
1     True
2    False
3    False
4    False
dtype: bool
'''
```

通过使用“ last”，将每组重复值的最后一次出现设置为False，将所有其他重复值设置为True。

```python
df.duplicated(keep='last')
'''
0     True
1    False
2    False
3    False
4    False
dtype: bool
'''
```

通过将keep设置为False，所有重复项都为True。

```python
df.duplicated(keep=False)
'''
0     True
1     True
2    False
3    False
4    False
dtype: bool
'''
```

要在特定列上查找重复项，请使用子集。

```python
df.duplicated(subset=['brand'])
'''
0    False
1     True
2    False
3     True
4     True
dtype: bool
'''
```

### 删除重复值 [drop_duplicates](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html?highlight=drop_duplicated)

删除重复值的语法为：

```pyhton
df.drop_duplicates(subset=None, 
                   keep='first', 
                   inplace=False, 
                   ignore_index=False)
```

subset指定的标签或标签序列可选，仅删除某些列重复项，默认情况为使用所有列，其他有：

- keep：确定要保留的重复项（如果有）
  - first : 保留第一次出现的重复项，默认
  - last : 保留最后一次出现的重复项。
  - False : 删除所有重复项
- inplac：False，是将副本放置在适当位置还是返回副本
- ignore_inde：如果为True, 则重新分配自然索引（0, 1, …, n - 1）

操作一下：

```pyhton
df = pd.DataFrame({
    'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],
    'style': ['cup', 'cup', 'cup', 'pack', 'pack'],
    'rating': [4, 4, 3.5, 15, 5]
})
df
'''
    brand style  rating
0  Yum Yum   cup     4.0
1  Yum Yum   cup     4.0
2  Indomie   cup     3.5
3  Indomie  pack    15.0
4  Indomie  pack     5.0
'''
```

默认情况下，它将基于所有列删除重复的行。

```pyhton
df.drop_duplicates()
'''
    brand style  rating
0  Yum Yum   cup     4.0
2  Indomie   cup     3.5
3  Indomie  pack    15.0
4  Indomie  pack     5.0
'''
```

要删除特定列上的重复项，请使用子集。

```pyhton
df.drop_duplicates(subset=['brand'])
'''
    brand style  rating
0  Yum Yum   cup     4.0
2  Indomie   cup     3.5
'''
```

要删除重复项并保留最后一次出现，请使用keep。

```pyhton
df.drop_duplicates(subset=['brand', 'style'], keep='last')
'''
    brand style  rating
1  Yum Yum   cup     4.0
2  Indomie   cup     3.5
4  Indomie  pack     5.0
'''
```
