# 数据合并

## 数据合并场景和操作

在实际的业务中，需要将多个文档、数据，可能是 Series 或 DataFrame 拼合在一起，进行大数据分析。Pandas 提供的各种功能轻而易举地进行这些工作。

#### 应用场景

在作者来看，在以下场景下可能会需要对数据进行拼接、合并操作：

- 日常工作中由多方交付的表格要合并成一个总表格
- 从数据库导出数据，单次太大，多次导出后需要合并
- 有多个数据，需要制取各自中有用的信息组成一个新的表
- 等等

#### 操作

数据的合并其实有合并、连接、拼接等几种，最简单的是连接。连接字段相同只是把新的内容追加在后边。合并可能是不同的列，把这些列组合在一起形成多个列。还有一种是混合的，在以上的基础上，合并过程中还需要做些计算。

## 数据连接 [concat](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html?highlight=concat#pandas.concat)

Pandas 数据的连接可以实现纵向和横向连接，将数据连接后会形成一个新的对象， Series 或 DataFrame。连接是最常用的多个数据合并操作。

`pd.concat()` 是专门用于数据连接合并的函数，它可以沿着行或者列进行操作，同时可以指定非合并轴的合并方式（合集、交集等）。可以详细参阅[pd.concat API 说明](https://www.gairuo.com/p/pandas-concat)。

#### 数据准备

以下有三个 df ，后续的操作我们将对他们进行合并处理。

```python
df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],
                    'B': ['B0', 'B1', 'B2', 'B3'],
                    'C': ['C0', 'C1', 'C2', 'C3'],
                    'D': ['D0', 'D1', 'D2', 'D3']},
                   index=[0, 1, 2, 3])


df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],
                    'B': ['B4', 'B5', 'B6', 'B7'],
                    'C': ['C4', 'C5', 'C6', 'C7'],
                    'D': ['D4', 'D5', 'D6', 'D7']},
                   index=[4, 5, 6, 7])


df3 = pd.DataFrame({'A': ['A8', 'A9', 'A10', 'A11'],
                    'B': ['B8', 'B9', 'B10', 'B11'],
                    'C': ['C8', 'C9', 'C10', 'C11'],
                    'D': ['D8', 'D9', 'D10', 'D11']},
                   index=[8, 9, 10, 11])
```

#### 基本连接

将三个有相同列的表合并到一起，并使用新的自然索引：

```python
frames = [df1, df2, df3]
df = pd.concat(frames)
```

![pandas 合并](https://www.gairuo.com/file/pic/2020/04/merging_concat_basic.png)

#### 指定索引

我们可以再给每个表给一个一级索引，形成多层索引：

```
df = pd.concat(frames, keys=['x', 'y', 'z'])
```

![pandas 合并](https://www.gairuo.com/file/pic/2020/05/merging_concat_keys.png)

```python
df.loc['y'] # 看一级索引 y
'''
    A   B   C   D
4  A4  B4  C4  D4
5  A5  B5  C5  D5
6  A6  B6  C6  D6
7  A7  B7  C7  D7
'''
```

#### 忽略索引

在合并不保留原索引，启用新的自然索引：

```python
result = pd.concat([df1, df4], ignore_index=True, sort=False)
```

![pandas 合并](https://www.gairuo.com/file/pic/2020/05/merging_concat_ignore_index.png)

#### 按列连接

按列进行连接，没有的值为空：

```python
df4 = pd.DataFrame({'B': ['B2', 'B3', 'B6', 'B7'],
                    'D': ['D2', 'D3', 'D6', 'D7'],
                    'F': ['F2', 'F3', 'F6', 'F7']},
                   index=[2, 3, 6, 7])
df = pd.concat([df1, df4], axis=1, sort=False)
```

![pandas 合并](https://www.gairuo.com/file/pic/2020/05/merging_concat_axis1.png)

#### 取交集

以上连接后得到了两个表内容的并集（默认是 `join ='outer'`），如果我们需要交集呢？

```python
df = pd.concat([df1, df4], axis=1, join='inner')
```

![pandas 合并](https://www.gairuo.com/file/pic/2020/05/merging_concat_axis1_inner.png)

可见只将以有共同索引的内容进行了合并。

#### 只取指定索引内容

如果我们只需要第一张表索引的内容，可以：

```python
# 以下两个方法效果一样
pd.concat([df1, df4], axis=1).reindex(df1.index)
pd.concat([df1, df4.reindex(df1.index)], axis=1)
```

![pandas 合并](https://www.gairuo.com/file/pic/2020/05/merging_concat_axis1_join_axes.png)

#### 与序列合并

不用维度的数据也可以合并，df 和 s 合并：

```python
s1 = pd.Series(['X0', 'X1', 'X2', 'X3'], name='X')
df = pd.concat([df1, s1], axis=1)
```

![pandas 合并](https://www.gairuo.com/file/pic/2020/05/merging_concat_mixed_ndim.png)

但是，还是建议使用 df.assign() 来定义一个新列。

如果序列没名称，会自动给写 012 之类的自然索引名称：

```python
s2 = pd.Series(['_0', '_1', '_2', '_3'])
df = pd.concat([df1, s2, s2, s2], axis=1)
```

![pandas 合并](https://www.gairuo.com/file/pic/2020/05/merging_concat_unnamed_series.png)

`ignore_index=True` 会取消原有列名：

```python
df = pd.concat([df1, s1], axis=1, ignore_index=True)
```

![pandas 合并](https://www.gairuo.com/file/pic/2020/05/merging_concat_series_ignore_index.png)

#### 指定新索引名

以下数据合并后的列名有：

```python
s3 = pd.Series([0, 1, 2, 3], name='foo')
s4 = pd.Series([0, 1, 2, 3])
s5 = pd.Series([0, 1, 4, 5])
pd.concat([s3, s4, s5], axis=1)
'''
   foo  0  1
0    0  0  0
1    1  1  1
2    2  2  4
3    3  3  5
'''
```

给定 keys 会采用新的列名:

```python
pd.concat([s3, s4, s5], axis=1, keys=['red', 'blue', 'yellow'])
'''
   red  blue  yellow
0    0     0       0
1    1     1       1
2    2     2       4
3    3     3       5
'''
```

如果是 df 连接行，则指定为索引名：

```python
df = pd.concat(frames, keys=['x', 'y', 'z'])
```

![pandas 合并](https://www.gairuo.com/file/pic/2020/05/merging_concat_group_keys2.png)

也可以用**字典**形式，定义各自表的索引名称：

```python
pieces = {'x': df1, 'y': df2, 'z': df3}
df = pd.concat(pieces)
```

![pandas 合并](https://www.gairuo.com/file/pic/2020/05/merging_concat_dict.png)

**只取字典中的部分：**

```python
df = pd.concat(pieces, keys=['z', 'y'])
```

![pandas 合并](https://www.gairuo.com/file/pic/2020/05/merging_concat_dict_keys.png)

多层数据的索引如下：

```python
result.index.levels
# FrozenList([['z', 'y'], [4, 5, 6, 7, 8, 9, 10, 11]])
```

如果希望指定其他级别（有时会这样），则可以使用level参数来指定：

```python
df = pd.concat(pieces, keys=['x', 'y', 'z'],
               levels=[['z', 'y', 'x', 'w']],
               names=['group_key'])
```

![pandas 合并](https://www.gairuo.com/file/pic/2020/05/merging_concat_dict_keys_names.png)

```python
df.index.levels
# FrozenList([['z', 'y', 'x', 'w'], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]])
```

`pd.concat()` 是最常用的数据连接工具，需要熟练掌握。

## 多文件数据合并

多文件合并在实际工作中还是比较常见的，汇总表往往费时费力，如果用代码帮我们去做就省力很多，而且还可以复用，就会节省大量时间。

### 多文件合并

最简单的方法是先单个把数据取出现来，然后进行合并。

```python
df1 = pd.DataFrame(data1)
df2 = pd.read_excel('tmp.xlsx')
df3 = pd.read_csv('tmp.csv')

merged_df = pd.concat([df1, df2, df3])
```

注意，不要一个一个地去用 concat，这样性能会很差，可以先把所有表格加到列表里，一次性合并：

```python
frames = [ process_your_file(f) for f in files ]
result = pd.concat(frames)
```

**一个包含多个 Sheet 的 Excel 合并成一个 DataFrame：**

```python
dfm = pd.read_excel('team.xlsx', sheet_name=None)
pd.concat(dfm.values())
pd.concat(dfm) # 保留 Sheet 名作为一级索引
```

### 读取目录文件

如果文件存在一个目录下，推荐方法：

```python
import glob
# 取出目录下所有 xlsx 格式文件
files = glob.glob("data/*.xlsx")
cols = ['记录ID', '开始时间', '名称'] # 只取这些列
# 列表推导出对象
dflist = [pd.read_excel(i, usecols=cols) for i in files]
df = pd.concat(dflist) # 合并
```

其他方法：

```python
# 多个文件
pd.concat(map(pd.read_csv, ['data/d1.csv',
                            'data/d2.csv',
                            'data/d3.csv']))

pd.concat(map(pd.read_excel, ['data/d1.xlsx',
                              'data/d2.xlsx',
                              'data/d3.xlsx']))

# 目录下所有文件
from os import listdir
filepaths = [f for f in listdir("./data") if f.endswith('.csv')]
df = pd.concat(map(pd.read_csv, filepaths))

# 方法 2
import glob
df = pd.concat(map(pd.read_csv, glob.glob('data/*.csv')))
df = pd.concat(map(pd.read_excel, glob.glob('data/*.xlsx')))
```

### 追加列合并

如果需要使用`pd.merge()`追加列合并时，由于此方法只能合并两个 DataFrame，因此可以用 reduce 来操作完成：

```python
from functools import reduce

df = reduce(lambda a, b: pd.merge(a, b, on=['记录ID']), dflist)
```

只要熟练使用其中一个方法就行。

## 数据追加 df.append

### 语法结构

## 语法结构

```python
df.append(self, other, ignore_index=False,
          verify_integrity=False, sort=False)
```

其中：

- other 是它要追加的其他 DataFrame 或者类似序列内容
- ignore_index 如果为 True 则重新进行自然索引
- verify_integrity 如果为 True 则遇到重复索引内容时报错
- sort 进行排序

### 同结构

将同结构的数据追加在原数据后边：

```python
result = df1.append(df2)
```

![image-20230426150739502](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20230426150739502.png)

### 不同结构 

不同结构的追加，没有的列会增加，没有对应内容的会为空：

```python
result = df1.append(df4, sort=False)
```

![image-20230426150807084](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20230426150807084.png)

### 追加合并多个

可以将多个 df 追加到原数据中：

```python
result = df1.append([df2, df3])
```

![image-20230426150850934](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20230426150850934.png)

### 忽略索引

在合并不保留原索引，启用新的自然索引：

```python
result = df1.append(df4, ignore_index=True, sort=False)
```

![pandas 合并](https://www.gairuo.com/file/pic/2020/05/merging_append_ignore_index.png)

### 追加序列

```python
s2 = pd.Series(['X0', 'X1', 'X2', 'X3'],
               index=['A', 'B', 'C', 'D'])
result = df1.append(s2, ignore_index=True)
```

![image-20230426150953660](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20230426150953660.png)

### 追加字典列表

```python
dicts = [{'A': 1, 'B': 2, 'C': 3, 'X': 4},
         {'A': 5, 'B': 6, 'C': 7, 'Y': 8}]
result = df1.append(dicts, ignore_index=True, sort=False)
```

![image-20230426151335330](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20230426151335330.png)

### 关于废弃

在 pandas 1.4 版本中宣布 append() 方法将被弃用，同时在这个版本中会进行警告，提示使用 pandas.concat()。

社区讨论废弃 append() 的主要原因为：

- Python 的 list 有 append() 方法，但 DataFrame/Series 的没有做原地操作，是一个不好的类比
- pandas.concat() 更灵活，它支持 axis，使类似操作更加统一
- concat 将是性能最好的，append 太慢

替代的操作也可以是：

```python
df.loc[len(df) + 1] = <new row>
df.loc[<new label>] = <new row>
```

如果想用链式，可以用 pipe() 调用：

```python
df2 = pd.DataFrame({"name": ["tomato"], "image": ["🍅"]})

(
    fruits.merge(veggies)
    .pipe(lambda df: pd.concat([df, df2], ignore_index=True))
)
```

### 参考

## 连接数据 [merge](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html?highlight=merge#pandas.DataFrame.merge)

### 语法结构

可以将两个 DataFrame 或者 Series 进行连接：

```python
pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None,
         left_index=False, right_index=False, sort=True,
         suffixes=('_x', '_y'), copy=True, indicator=False,
         validate=None)
```

可以实现类似 SQL 的 join 操作，参数为：

- how：连接方式，默认为inner，可设为inner/outer/left/right
- on：根据某个字段进行连接，必须存在于两个DateFrame中（若未同时存在，则需要分别使用left_on 和 right_on 来设置）
- left_on：左连接，以DataFrame1中用作连接键的列
- right_on：右连接，以DataFrame2中用作连接键的列
- left_index：bool, default False，将DataFrame1行索引用作连接键
- right_index：bool, default False，将DataFrame2行索引用作连接键
- sort：根据连接键对合并后的数据进行排列，默认为True
- suffixes：对两个数据集中出现的重复列，新数据集中加上后缀 _x, _y 进行区别

### 连接键

```python
left = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],
                     'A': ['A0', 'A1', 'A2', 'A3'],
                     'B': ['B0', 'B1', 'B2', 'B3']})

right = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],
                      'C': ['C0', 'C1', 'C2', 'C3'],
                      'D': ['D0', 'D1', 'D2', 'D3']})

pd.merge(left, right, on='key')
```

![pandas merge](https://www.gairuo.com/file/pic/2020/05/merging_merge_on_key.png)

`on` 为两个数据的连接键，都以 key 为标准。

### 多个连接键

有多个连接键，将两个表按多个关键点（交叉点）连接，默认情况下how=“inner”，会得到一两个数据的交集。

```python
left = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],
                     'key2': ['K0', 'K1', 'K0', 'K1'],
                     'A': ['A0', 'A1', 'A2', 'A3'],
                     'B': ['B0', 'B1', 'B2', 'B3']})


right = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],
                      'key2': ['K0', 'K0', 'K0', 'K0'],
                      'C': ['C0', 'C1', 'C2', 'C3'],
                      'D': ['D0', 'D1', 'D2', 'D3']})

pd.merge(left, right, on=['key1', 'key2'])
```

![image-20230426152259768](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20230426152259768.png)

key1 和 key2 组合在两个表里共有的会被连接，两个表都有 `(k1, k0)` ，右表有两个，左表有一个，合并后右表共同了左表的内容。

### 连接方法 how

`how` 参数可以指定数据用哪种方法进行合并，没有的内容会为 NaN：

```python
# 以左为表基表
pd.merge(left, right, how='left', on=['key1', 'key2'])
```

![pandas merge left](https://www.gairuo.com/file/pic/2020/05/merging_merge_on_key_left.png)

```python
# 以右为表基表
pd.merge(left, right, how='right', on=['key1', 'key2'])
```

![pandas merge right](https://www.gairuo.com/file/pic/2020/05/merging_merge_on_key_right.png)

```python
# 取两个表的合集
pd.merge(left, right, how='outer', on=['key1', 'key2'])
```

![pandas merge outer](https://www.gairuo.com/file/pic/2020/05/merging_merge_on_key_outer.png)

```python
# 取两个表的交集
pd.merge(left, right, how='inner', on=['key1', 'key2'])
```

![pandas merge inner](https://www.gairuo.com/file/pic/2020/05/merging_merge_on_key_inner.png)

下边是一个有重复连接键的例子：

```python
left = pd.DataFrame({'A': [1, 2], 'B': [2, 2]})
right = pd.DataFrame({'A': [4, 5, 6], 'B': [2, 2, 2]})
pd.merge(left, right, on='B', how='outer')
```

![pandas merge key_dup](https://www.gairuo.com/file/pic/2020/05/merging_merge_on_key_dup.png)

### 检查重复键 validate

```python
# 一对多连接
left = pd.DataFrame({'A' : [1,2], 'B' : [1, 2]})
right = pd.DataFrame({'A' : [4,5,6], 'B': [2, 2, 2]})
pd.merge(left, right, on='B', how='outer', validate="one_to_many")
```

其他的还有：

如果指定，则检查合并是否为指定的类型：

- “one_to_one” 或 “1:1”: 检查合并键在左右数据集中是否唯一
- “one_to_many” 或 “1:m”: 检查合并键在左数据集中是否唯一
- “many_to_one” 或 “m:1”: 检查合并键在右数据集中是否唯一
- “many_to_many” 或 “m:m”: 允许，但不会检查

### 连接指示 indicator

如果设置 indicator 为 True, 则会增加名为 `_merge` 的一列，显示这列是多何而来，_merge 列有取三个值：

- left_only 只在左表中
- right_only 只在右表中
- both 两个表中都有

```python
pd.merge(left, right, on='B', how='outer', indicator=True)

'''
   A_x  B  A_y     _merge
0    1  1  NaN  left_only
1    2  2  4.0       both
2    2  2  5.0       both
3    2  2  6.0       both
'''
```

### join 多个 dataframe

df.join(df2) 可以连用对多个数据完成合并拼接：

```python
df.join(df2) # 按索引连接
left.join([right, right2]) # 连接多个表
# 支持的参数 lsuffix/rsuffix 为左右表后缀
df1.join(other, on=None, how='left', lsuffix='', rsuffix='', sort=False)
```

### 其他操作

```python
# df 也有 merge 方法，用户与 pd.merge 相同
left.merge(right, how='inner')
# 按索引连接
pd.merge(left, right, left_index=True, right_index=True, how='inner')
# 列和索引连接
left.join(right, on=key_or_keys)
result = left.join(right, on=['key1', 'key2'])
pd.merge(left, right, left_on=key_or_keys, right_index=True,
      how='left', sort=False)

# 连接方式
result = left.join(right, how='inner')
# 取消索引按列连接
pd.merge(left.reset_index(), right.reset_index(),
         on=['key'], how='inner').set_index(['key', 'Y'])
```

## 时序数据合并

### [pd.merge_ordered](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge_ordered.html?highlight=merge_ordered#pandas.merge_ordered)

`pd.merge_ordered` 函数允许组合时间序列和其他有序数据。 特别是，它具有可选的fill_method 关键字来填充/插入丢失的数据：

```python
left = pd.DataFrame({'k': ['K0', 'K1', 'K1', 'K2'],
                     'lv': [1, 2, 3, 4],
                     's': ['a', 'b', 'c', 'd']})

right = pd.DataFrame({'k': ['K1', 'K2', 'K4'],
                      'rv': [1, 2, 3]})

pd.merge_ordered(left, right, fill_method='ffill', left_by='s')
'''
     k   lv  s   rv
0   K0  1.0  a  NaN
1   K1  1.0  a  1.0
2   K2  1.0  a  2.0
3   K4  1.0  a  3.0
4   K1  2.0  b  1.0
5   K2  2.0  b  2.0
6   K4  2.0  b  3.0
7   K1  3.0  c  1.0
8   K2  3.0  c  2.0
9   K4  3.0  c  3.0
10  K1  NaN  d  1.0
11  K2  4.0  d  2.0
12  K4  4.0  d  3.0
'''
```

按照 s 列的顺序进行了排序，它也适用于时间类型的数据。

按照left_by排序时，另外两列的数据是 k0, k1, k2, k4, k1,k2,k4, k1,k2,k4, k1,k2,k4,它会以s为基准，每次去right找不存在的加上去。

### [pd.merge_asof](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge_asof.html?highlight=merge_asof#pandas.merge_asof)

执行 asof 合并（as of 意为自……起；到…时候为止），这类似于左连接，只是我们匹配最近的关键点（on 参数指定）而不是相等的关键点。两个 DataFrame 必须按键排序。

语法为：

```python
pd.merge_asof(left, right, on=None,
              left_on=None, right_on=None,
              left_index=False, right_index=False,
              by=None, left_by=None, right_by=None,
              suffixes=('_x', '_y'), tolerance=None,
              allow_exact_matches=True,
              direction='backward')
```

其中 on 参数的值代表的列名，必须在两个数据帧中都找到，必须对数据进行排序。此外，这必须是可以数字化的列，如 datetimelike（时间的各种类型）, integer, float。必须要不给出参数 On 要么给出 left_on/right_on。

先上个例子：

```python
left = pd.DataFrame({'a': [1, 5, 10], 'left_val': ['a', 'b', 'c']})
left
'''    a left_val
0   1        a
1   5        b
2  10        c
'''

right = pd.DataFrame({'a': [1, 2, 3, 6, 7],
                      'right_val': [1, 2, 3, 6, 7]})
right
'''   a  right_val
0  1          1
1  2          2
2  3          3
3  6          6
4  7          7
'''

# 按 a 连接
pd.merge_asof(left, right, on='a')
'''    a left_val  right_val
0   1        a          1
1   5        b          3
2  10        c          7
'''
```

以上例中左表（基准表）与右表按共同的 a 列进行合并，在拼合 right_val 列时：

- a=1，右表有对应值，为 1
- a=5，右表无对应值，由于参数默认 direction='backward' 则“向后”搜索选择右表中“on”键小于或等于左键的最后一行，与 5 较小的是 3，取 3
- a=10，右表无对应值，同上，与 10 较小的是 7，取 7

参数 direction 还可以取以下值：

- “backward” 向后，搜索选择右数据中“on”键小于或等于左键的最后一行，比它小的里边最大的。
- “forward” 向前，搜索选择右侧数据中的第一行，其“on”键大于或等于左侧的键，比它大的里边最大的。
- “nearest” 最近，搜索选择右侧数据中的行，该行的“on”键在绝对距离上最接近左侧的键，和它差值绝对值最小的。

参数 direction 的例子：

```
# 向前
pd.merge_asof(left, right, on="a", direction="forward")
'''
    a left_val  right_val
0   1        a        1.0
1   5        b        6.0
2  10        c        NaN
'''

# 邻近
pd.merge_asof(left, right, on="a", direction="nearest")
'''
    a left_val  right_val
0   1        a          1
1   5        b          6
2  10        c          7
'''
pd.merge_asof(left, right, on='a', allow_exact_matches=False)
'''    a left_val  right_val
0   1        a        NaN
1   5        b        3.0
2  10        c        7.0
'''
```

参数 allow_exact_matches 的意思是：

- 如为 True（默认）, 允许与相同的值匹配（即小于或等于/大于或等于）
- 如为 False, 不匹配相同的值（即严格要求小于/大于，就是不能等于）

上例设置为 False，a=1 时，由于右表有同样的值，就不匹配了，给出了一个缺失值。

这个方法经常用于合并时间相关的数据，由于时间数据在合并时有细微的差别，不能完全匹配，就需要找到邻近的值使用。以下是时间相关的案例：

```python
quotes
'''                     time ticker     bid     ask
0 2016-05-25 13:30:00.023   GOOG  720.50  720.93
1 2016-05-25 13:30:00.023   MSFT   51.95   51.96
2 2016-05-25 13:30:00.030   MSFT   51.97   51.98
3 2016-05-25 13:30:00.041   MSFT   51.99   52.00
4 2016-05-25 13:30:00.048   GOOG  720.50  720.93
5 2016-05-25 13:30:00.049   AAPL   97.99   98.01
6 2016-05-25 13:30:00.072   GOOG  720.50  720.88
7 2016-05-25 13:30:00.075   MSFT   52.01   52.03'''

trades
'''                     time ticker   price  quantity
0 2016-05-25 13:30:00.023   MSFT   51.95        75
1 2016-05-25 13:30:00.038   MSFT   51.95       155
2 2016-05-25 13:30:00.048   GOOG  720.77       100
3 2016-05-25 13:30:00.048   GOOG  720.92       100
4 2016-05-25 13:30:00.048   AAPL   98.00       100'''

pd.merge_asof(trades, quotes,
                      on='time',
                      by='ticker')
'''                     time ticker   price  quantity     bid     ask
0 2016-05-25 13:30:00.023   MSFT   51.95        75   51.95   51.96
1 2016-05-25 13:30:00.038   MSFT   51.95       155   51.97   51.98
2 2016-05-25 13:30:00.048   GOOG  720.77       100  720.50  720.93
3 2016-05-25 13:30:00.048   GOOG  720.92       100  720.50  720.93
4 2016-05-25 13:30:00.048   AAPL   98.00       100     NaN     NaN'''

pd.merge_asof(trades, quotes,
                      on='time',
                      by='ticker',
                      tolerance=pd.Timedelta('2ms'))
'''                     time ticker   price  quantity     bid     ask
0 2016-05-25 13:30:00.023   MSFT   51.95        75   51.95   51.96
1 2016-05-25 13:30:00.038   MSFT   51.95       155     NaN     NaN
2 2016-05-25 13:30:00.048   GOOG  720.77       100  720.50  720.93
3 2016-05-25 13:30:00.048   GOOG  720.92       100  720.50  720.93
4 2016-05-25 13:30:00.048   AAPL   98.00       100     NaN     NaN'''

pd.merge_asof(trades, quotes,
                      on='time',
                      by='ticker',
                      tolerance=pd.Timedelta('10ms'),
                      allow_exact_matches=False)
'''                     time ticker   price  quantity     bid     ask
0 2016-05-25 13:30:00.023   MSFT   51.95        75     NaN     NaN
1 2016-05-25 13:30:00.038   MSFT   51.95       155   51.97   51.98
2 2016-05-25 13:30:00.048   GOOG  720.77       100     NaN     NaN
3 2016-05-25 13:30:00.048   GOOG  720.92       100     NaN     NaN
4 2016-05-25 13:30:00.048   AAPL   98.00       100     NaN     NaN'''
```

tolerance 参数可传入一个时长数据（Timedelta，在非时间数据情况下可以传入一个 int），表示能够容易的差距范围，必须与合并索引兼容。

## 逐元素合并

### df.combine_first() [combine_first](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.combine_first.html?highlight=combine_first#pandas.DataFrame.combine_first)

使用相同位置的值更新空元素，它只能是 df1 有空元素时才能被替换，如果数据结构不一致，所得 DataFram e的行索引和列索引将是两者的并集。

```python
df1 = pd.DataFrame({'A': [None, 0], 'B': [None, 4]})
df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})
df1.combine_first(df2)
'''
     A    B
0  1.0  3.0
1  0.0  4.0
'''
```

在上例中，df1 中的 A 和 B 的空值被 df2 中的相同位置值替换。

```python
df1 = pd.DataFrame({'A': [None, 0], 'B': [4, None]})
df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1]}, index=[1, 2])
df1.combine_first(df2)
'''
     A    B    C
0  NaN  4.0  NaN
1  0.0  3.0  1.0
2  NaN  3.0  1.0
'''
```

在上例中，df1 中的 A 中的空值由于没有相同位置值来替换，仍然为空。

### df.combine() [combine](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.combine.html?highlight=combine#pandas.DataFrame.combine)

可以与另一个 DataFrame 进行按列组合。使用函数将一个 DataFrame 与其他DataFrame合并，以逐元素合并列。 所得 DataFrame 的行索引和列索引将是两者的并集。

这个函数中有两个参数，分别是两个 df 中对应的 series， 计算后返回一个 Series 或者标量。

```python
df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})
df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})
# s1 列总和如果小于 s2列总和取 s1, 否则取 s2
take_smaller = lambda s1, s2: s1 if s1.sum() < s2.sum() else s2
df1.combine(df2, take_smaller)
'''
A  B
0  0  3
1  0  3
'''
```

也可以直接使用 numpy 的函数：

```python
df1 = pd.DataFrame({'A': [5, 0], 'B': [2, 4]})
df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})
# 每个对应元素中最小的
df1.combine(df2, np.minimum)
   A  B
0  1  2
1  0  3
```

对于空值缺失值可以指定填充值，填充完后代入计算：

```python
df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})
df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})
df1.combine(df2, take_smaller, fill_value=-5)
'''
A    B
0  0 -5.0
1  0  4.0'
''
```

但是，如果两个数据帧中的相同元素均为“无”，则将保留“无”：

```python
df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})
df2 = pd.DataFrame({'A': [1, 1], 'B': [None, 3]})
df1.combine(df2, take_smaller, fill_value=-5)
'''
A    B
0  0 -5.0
1  0  3.0
'''
```

以下是轴不同时合并覆盖和行为，均会为空值。

```python
df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})
df2 = pd.DataFrame({'B': [3, 3], 'C': [-10, 1], }, index=[1, 2])
df1.combine(df2, take_smaller)
'''
A    B     C
0  NaN  NaN   NaN
1  NaN  3.0 -10.0
2  NaN  3.0   1.0
'''
# overwrite 不存在的列将不被NaN覆盖
df1.combine(df2, take_smaller, overwrite=False)
'''
A    B     C
0  0.0  NaN   NaN
1  0.0  3.0 -10.0
2  NaN  3.0   1.0
'''
```

以下是不同行索引的示例：

```python
df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1], }, index=[1, 2])
df2.combine(df1, take_smaller)
   A    B   C
0  0.0  NaN NaN
1  0.0  3.0 NaN
2  NaN  3.0 NaN

df2.combine(df1, take_smaller, overwrite=False)
     A    B   C
0  0.0  NaN NaN
1  0.0  3.0 1.0
2  NaN  3.0 1.0
```

### df.update()

使用来自另一个 DataFrame 的非NA值进行修改，原 df 为被更新。

```python
df = pd.DataFrame({'A': [1, 2, 3],
                   'B': [400, 500, 600]})
new_df = pd.DataFrame({'B': [4, 5, 6],
                       'C': [7, 8, 9]})
df.update(new_df)
df
   A  B
0  1  4
1  2  5
2  3  6
```

DataFrame的长度不会增加，只会更新匹配的索引/列标签上的值。

```python
df = pd.DataFrame({'A': ['a', 'b', 'c'],
                   'B': ['x', 'y', 'z']})
new_df = pd.DataFrame({'B': ['d', 'e', 'f', 'g', 'h', 'i']})
df.update(new_df)
df
   A  B
0  a  d
1  b  e
2  c  f
```

对于系列，必须设置其名称属性。

```python
df = pd.DataFrame({'A': ['a', 'b', 'c'],
                   'B': ['x', 'y', 'z']})
new_column = pd.Series(['d', 'e'], name='B', index=[0, 2])
df.update(new_column)
df
   A  B
0  a  d
1  b  y
2  c  e


df = pd.DataFrame({'A': ['a', 'b', 'c'],
                   'B': ['x', 'y', 'z']})
new_df = pd.DataFrame({'B': ['d', 'e']}, index=[1, 2])
df.update(new_df)
df
   A  B
0  a  x
1  b  d
2  c  e
```

如果其他包含NaN，则相应的值不会在原始数据帧中更新。

```python
df = pd.DataFrame({'A': [1, 2, 3],
                   'B': [400, 500, 600]})
new_df = pd.DataFrame({'B': [4, np.nan, 6]})
df.update(new_df)
df
   A      B
0  1    4.0
1  2  500.0
2  3    6.0
```

## 相关内容

## 数据对比 [compare](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.compare.html?highlight=compare#pandas.DataFrame.compare)

df.compare() 和s.compare() 方法使您可以分别比较两个DataFrame 或 Series，并总结它们之间的差异。V1.1.0 中添加了此功能。



### 语法

语法如下：

```python
pd.compare(other, align_axis=1, keep_shape=False, keep_equal=False)
```

其中：

- other：被对比的数据
- align_axis=1：差异堆叠在列/行上
- keep_shape=False：不保留相等的值
- keep_equal=False：不保留所有原始行和列

### 用法

例如，您可能想要比较两个DataFrame并排堆叠它们的差异。



```python
df = pd.DataFrame(
    {
        "col1": ["a", "a", "b", "b", "a"],
        "col2": [1.0, 2.0, 3.0, np.nan, 5.0],
        "col3": [1.0, 2.0, 3.0, 4.0, 5.0]
    },
    columns=["col1", "col2", "col3"],
)
df
'''
  col1  col2  col3
0    a   1.0   1.0
1    a   2.0   2.0
2    b   3.0   3.0
3    b   NaN   4.0
4    a   5.0   5.0
'''

# 对数据进行修改以便进行对比
df2 = df.copy()
df2.loc[0, 'col1'] = 'c'
df2.loc[2, 'col3'] = 4.0

df2
'''
  col1  col2  col3
0    c   1.0   1.0
1    a   2.0   2.0
2    b   3.0   4.0
3    b   NaN   4.0
4    a   5.0   5.0
'''
```

应用对比：

```python
df.compare(df2)
'''
  col1       col3
  self other self other
0    a     c  NaN   NaN
2  NaN   NaN  3.0   4.0
'''
```

默认情况下，如果两个对应的值相等，它们将显示为NaN。 此外，如果整个行/列中的所有值都将从结果中省略。 其余差异将在列上对齐。

### 其他方法

还可以传入以下参数：

```python
df = pd.DataFrame(
    {
        "col1": ["a", "a", "b", "b", "a"],
        "col2": [1.0, 2.0, 3.0, np.nan, 5.0],
        "col3": [1.0, 2.0, 3.0, 4.0, 5.0]
    },
    columns=["col1", "col2", "col3"],
)

df
'''
  col1  col2  col3
0    a   1.0   1.0
1    a   2.0   2.0
2    b   3.0   3.0
3    b   NaN   4.0
4    a   5.0   5.0
'''
```

修改数据，方便对比：

```python
df2 = df.copy()
df2.loc[0, 'col1'] = 'c'
df2.loc[2, 'col3'] = 4.0
df2
'''
  col1  col2  col3
0    c   1.0   1.0
1    a   2.0   2.0
2    b   3.0   4.0
3    b   NaN   4.0
4    a   5.0   5.0
'''
```

显示有差异的列：

```python
df.compare(df2)
'''
  col1       col3
  self other self other
0    a     c  NaN   NaN
2  NaN   NaN  3.0   4.0
'''
```

将差异堆叠在行上：

```python
df.compare(df2, align_axis=0)
'''
        col1  col3
0 self     a   NaN
  other    c   NaN
2 self   NaN   3.0
  other  NaN   4.0
'''
```

保留相等的值：

```python
df.compare(df2, keep_equal=True)
'''
  col1       col3
  self other self other
0    a     c  1.0   1.0
2    b     b  3.0   4.0
'''
```

保留所有原始行和列：

```python
df.compare(df2, keep_shape=True)
'''
  col1       col2       col3
  self other self other self other
0    a     c  NaN   NaN  NaN   NaN
1  NaN   NaN  NaN   NaN  NaN   NaN
2  NaN   NaN  NaN   NaN  3.0   4.0
3  NaN   NaN  NaN   NaN  NaN   NaN
4  NaN   NaN  NaN   NaN  NaN   NaN
'''
```

保留所有原始行和列以及所有原始值：

```python
df.compare(df2, keep_shape=True, keep_equal=True)
'''
  col1       col2       col3
  self other self other self other
0    a     c  1.0   1.0  1.0   1.0
1    a     a  2.0   2.0  2.0   2.0
2    b     b  3.0   3.0  3.0   4.0
3    b     b  NaN   NaN  4.0   4.0
4    a     a  5.0   5.0  5.0   5.0
'''
```

### 数据相同 [equals](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.equals.html?highlight=equals#pandas.DataFrame.equals)

此外，还可以使用`df1.equals(df2)`来对比两个数据是否一致，测试两个对象是否包含相同的元素。



此功能允许将两个Series或DataFrame相互比较，以查看它们是否具有相同的形状和元素。 相同位置的NaN被认为是相等的。 列标题不必具有相同的类型，但是列中的元素必须具有相同的dtype。



此功能要求元素与其他Series或DataFrame中的元素具有相同的dtype。 但是，列标签不必具有相同的类型，只要它们仍被视为相等即可。



```python
df = pd.DataFrame({1: [10], 2: [20]})
df
    1   2
0  10  20
```

DataFrames df和fully_equal的元素和列标签具有相同的类型和值，它们将返回True。

```python
exactly_equal = pd.DataFrame({1: [10], 2: [20]})
exactly_equal
'''
    1   2
0  10  20
'''
df.equals(exactly_equal)
# True
```

DataFrames df和different_column_type具有相同的元素类型和值，但列标签具有不同的类型，它们仍将返回True。

```python
different_column_type = pd.DataFrame({1.0: [10], 2.0: [20]})
different_column_type
'''
   1.0  2.0
0   10   20
'''
df.equals(different_column_type)
# True
```

DataFrames df和different_data_type为其元素的相同值具有不同的类型，即使它们的列标签具有相同的值和类型，它们也将返回False。

```python
different_data_type = pd.DataFrame({1: [10.0], 2: [20.0]})
different_data_type
'''
      1     2
0  10.0  20.0
'''
df.equals(different_data_type)
# False
```

### 数据对齐

DataFrame.align 不会组合两个数据帧，但是可以将它们对齐，以便两个数据帧具有相同的行和/或列配置。我们看一个例子：

```python
df1 = pd.DataFrame([[1,2,3,4], [6,7,8,9]], 
                   columns=['D', 'B', 'E', 'A'],
                   index=[1,2])

df2 = pd.DataFrame([[10,20,30,40], [60,70,80,90], [600,700,800,900]],
                   columns=['A', 'B', 'C', 'D'],
                   index=[2,3,4])

df1
'''
   D  B  E  A
1  1  2  3  4
2  6  7  8  9
'''
df2
'''
     A    B    C    D
2   10   20   30   40
3   60   70   80   90
4  600  700  800  900
'''
```

让我们对齐这两个数据帧，按列对齐（axis=1），并对列标签执行外部联接（join='outer'）：

```python
a1, a2 = df1.align(df2, join='outer', axis=1)
print(a1)
print(a2)
'''
   A  B   C  D  E
1  4  2 NaN  1  3
2  9  7 NaN  6  8

A    B    C    D   E
2   10   20   30   40 NaN
3   60   70   80   90 NaN
4  600  700  800  900 NaN
'''
```

这里有几点需要注意：

- df1中的列已重新排列，以便与df2中的列对齐。
- 有一个标记为“C”的列已添加到df1，还有一个标记为“E”的列已添加到df2。这些列已用NaN填充。这是因为我们对列标签执行了外部联接。
- 数据帧内的所有值均未更改。
- 行标签未对齐；df2有第3行和第4行，而df1没有。这是因为我们要求对列进行对齐（轴=1）。

如果我们在行和列上对齐，但将join参数更改为“right”，会发生什么情况？

```python
a1, a2 = df1.align(df2, join='right', axis=None)
print(a1)
print(a2)
'''
     A    B   C    D
2  9.0  7.0 NaN  6.0
3  NaN  NaN NaN  NaN
4  NaN  NaN NaN  NaN

     A    B    C    D
2   10   20   30   40
3   60   70   80   90
4  600  700  800  900
'''
```

总之，如果要确保两个数据帧之间的行和/或列的排列相同，而不改变两个数据帧中包含的任何数据，请使用 DataFrame.align()。Series 也支持此方法。

更多内容查看：[align()](https://www.gairuo.com/p/pandas-align) 数据对齐方法介绍。

