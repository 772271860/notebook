# 基础功能

## pandas 功能介绍

**python 中四分位数求位置的方法是( n-1 )**:

**q1 = 1 + (n-1) * 0.25**

**q2 = 1 + (n-1) * 0.5**

**q3 = 1 + (n-1) * 0.75**

## 文件读取和导出

| 格式   | 文件格式      | 读取函数                                                     | 写入（输出）函数 |
| ------ | ------------- | ------------------------------------------------------------ | ---------------- |
| binary | Excel         | [read_excel](https://www.gairuo.com/p/pandas-read-excel)     | to_excel         |
| text   | CSV           | [read_csv](https://www.gairuo.com/p/pandas-read-csv) read_table | to_csv           |
| text   | JSON          | read_json                                                    | to_json          |
| text   | 网页表格 HTML | read_html                                                    | to_html          |
| text   | 剪贴板        | read_clipboard                                               | to_clipboard     |
| SQL    | SQL           | read_sql                                                     | to_sql           |
| XML    | read_xml      |                                                              | read_xml         |
| text   | Markdown      |                                                              | to_markdown      |

[官网文档](https://pandas.pydata.org/docs/user_guide/io.html)。

其中:

- 读取函数一般会赋值给一个变量 df , df = pd.read_xxxx()
- 输出函数是将变量自身进行操作并输出 df.to_xxxx()

### Csv

从csv文件中读取 DataFrame：

> **文件**

```python
# 文件目录
pd.read_csv('data.csv') # 如果文件与代码文件在同目录下
pd.read_csv('data/my/data.csv') # 指定目录
pd.read_csv('data/my/my.data') # CSV 文件扩展名不一定是 csv
# 使用网址 url
pd.read_csv('https://www.gairuo.com/file/data/dataset/GDP-China.csv')

# 也可以从 StringIO 中读取
from io import StringIO
data = ('col1,col2,col3\n'
        'a,b,1\n'
        'a,b,2\n'
        'c,d,3')
pd.read_csv(StringIO(data))
```

注：csv 文件扩展名不一定是 `.csv`

> **指定分隔符号**

```python
# 数据分隔转化是逗号, 如果是其他可以指定
pd.read_csv(data, sep='\t') # 制表符分隔 tab
pd.read_table(data) # read_table 默认是制表符分隔 tab
```

> **列、索引、名称**

```
 # 默认第一行是表头，可以指定，如果指定列名会被忽略
pd.read_csv(data, header=0)
pd.read_csv(data, header=None) # 没有表头
pd.read_csv(data, names=['列1', '列2']) # 指定列名列表
# 如没列名，自动指定一个: 前缀加序数
pd.read_csv(data, prefix='c_', header=None)

# 读取部分列
pd.read_csv(data, usecols=[0,4,3]) # 按索引只读取指定列，顺序无关
pd.read_csv(data, usecols=['列1', '列5']) # 按索引只读取指定列

# 指定列顺序，其实是 df 的筛选功能
pd.read_csv(data, usecols=['列1', '列5'])[['列5', '列1']]
pd.read_csv(data, index_col=0) # 第几列是索引
# 以下用 callable 方式可以巧妙指定顺序, in 后边的是我们要的顺序
pd.read_csv(data, usecols=lambda x: x.upper() in ['COL3', 'COL1'])
```

> **数据类型**

```python
data = 'https://www.gairuo.com/file/data/dataset/GDP-China.csv'
# 指定数据类型
pd.read_csv(data, dtype=np.float64) # 所有数据均为此数据类型
pd.read_csv(data, dtype={'c1':np.float64, 'c2': str}) # 指定字段的类型

# 解析日期时间
pd.read_csv(data, parse_dates=True) # 自动解析日期时间格式
pd.read_csv(data, parse_dates=['年份']) # 指定日期时间字段进行解析
# 将 1、4 列合并解析成名为 时间的 时间类型列
pd.read_csv(data, parse_dates={'时间':[1,4]})
# 指定时间解析库，默认是 dateutil.parser.parser
pd.read_csv(data, date_parser=pd.io.date_converters.parse_date_time)
date_parser=lambda x: pd.to_datetime(x, utc=True, format=...)
```

更多功能可参考 [pandas.read_csv 详细使用](https://www.gairuo.com/p/pandas-read-csv)。

> **导出文件**

```python
df.to_csv('done.csv')
df.to_csv('data/done.csv') # 可以指定文件目录路径
df.to_csv('done.csv', index=False) # 不要索引
# 导出二进制文件句柄（缓冲）, 支持编码和压缩 pandas 1.2.0 增加
import io
buffer = io.BytesIO()
df.to_csv(buffer, encoding="utf-8", compression="gzip")
# 指定一列导出 txt 格式文件
df.Q1.to_csv('Q1_test.txt', index=None)
```

### Excel

read_excel() 方法可以使用 xlrd Python 模块（可能需要安装，下同）读取 Excel 2003（.xls）文件。 可以使用 xlrd 或 openpyxl 读取Excel 2007+（.xlsx）文件，强烈建议安装 openpyxl。 可以使用 pyxlsb 读取二进制Excel（.xlsb）文件。 to_excel() 实例方法用于将 DataFrame 保存到 Excel。 大多数用法类似于 csv，包括文件的读取和保存。

```
xlsx = pd.ExcelFile('data.xlsx')
df = pd.read_excel(xlsx, 'Sheet1') # 读取
xlsx.parse('sheet1') # 取指定标签为 DataFrame
# Excel 的所有标签
xlsx.sheet_names
# ['sheet1', 'sheet2', 'sheet3', 'sheet4']
```

> **文件读取**

```python
# Returns a DataFrame
pd.read_excel('team.xlsx') # 默认读取第一个标签页 Sheet
pd.read_excel('path_to_file.xls', sheet_name='Sheet1') # 指定 Sheet
# 从网址 url 读取
pd.read_excel('https://www.gairuo.com/file/data/dataset/team.xlsx')
# !!! 读取的功能基本与 read_csv 一样，可参考上文
# 不指定索引，不指定表头，使用自动行列索引
pd.read_excel('tmp.xlsx', index_col=None, header=None)
# 指定列的数据类型
pd.read_excel('tmp.xlsx', index_col=0,
              dtype={'Name': str, 'Value': float})
```

多个 Sheet 的读取：

```
pd.read_excel('path_to_file.xls', sheet_name=['Sheet1', 'Sheet2'])
```

ExcelFile 对象：

```python
# 使用 ExcelFile 保存文件对象
xlsx = pd.ExcelFile('path_to_file.xls')
df = pd.read_excel(xlsx, 'Sheet1')

# 可以把多个 Sheet 存入 ExcelFile
with pd.ExcelFile('path_to_file.xls') as xls:
    df1 = pd.read_excel(xls, 'Sheet1')
    df2 = pd.read_excel(xls, 'Sheet2')
df = pd.read_excel(xlsx)
```

常用的参数使用与 [read_csv](https://www.gairuo.com/p/pandas-read-csv) 相同，详细参数可以通过[pandas.read_excel](https://www.gairuo.com/p/pandas-read-excel)阅读。

> **导出 excel**

```python
df.to_excel('path_to_file.xlsx')
# 指定 sheet 名, 不要索引
df.to_excel('path_to_file.xlsx', sheet_name='Sheet1', index=False)
# 指定索引名，不合并单元格
df.to_excel('path_to_file.xlsx', index_label='label', merge_cells=False)
# 将多个 df 分不同 sheet 导入到一个 excel
with pd.ExcelWriter('path_to_file.xlsx') as writer:
    df1.to_excel(writer, sheet_name='Sheet1')
    df2.to_excel(writer, sheet_name='Sheet2')

# 指定操作引擎
df.to_excel('path_to_file.xlsx', sheet_name='Sheet1', engine='xlsxwriter')
# By setting the 'engine' in the ExcelWriter constructor.
writer = pd.ExcelWriter('path_to_file.xlsx', engine='xlsxwriter')
df.to_excel(writer)
writer.save()

# 设置系统引擎
from pandas import options  # noqa: E402
options.io.excel.xlsx.writer = 'xlsxwriter'
df.to_excel('path_to_file.xlsx', sheet_name='Sheet1')
# 保留一位小数
df.to_excel(writer,'Sheet1',float_format = "%0.1f")
```

### JSON 

Pandas 可以读取和生成 Json 字符串，Series 或 DataFrame 都可以被转换。JSON 格式在网络上非常通用，在写爬虫时可以使用极大提高效率，在做可视化时前端的 JS 库往往需要接受 Json 格式。

> **读取 JSON**

最简单的读取 json 文件的方法是用 `pd.read_json('data.json')`：

```python
pd.read_json('data.json')
json = '''{"columns":["col 1","col 2"],
"index":["row 1","row 2"],
"data":[["a","b"],["c","d"]]}
'''
pd.read_json(json)
pd.read_json(json, orient='split') # json 格式
'''
orient 支持：
- 'split' : dict like {index -> [index], columns -> [columns], data -> [values]}
- 'records' : list like [{column -> value}, ... , {column -> value}]
- 'index' : dict like {index -> {column -> value}}
- 'columns' : dict like {column -> {index -> value}}
'''
```

对于复杂的 json 数据，可以使用 [pd.json_normalize()](https://www.gairuo.com/p/pandas-json-normalize)，它能读取半结构化 JSON。

> **输出 JSON**

Series 或 DataFrame 转换 JSON 的机制如下：

- Series :
  - 默认为 index
  - 支持 {split, records, index}
- DataFrame
  - 默认为 columns
  - 支持 {split, records, index, columns, values, table}

```python
df = pd.DataFrame([['a', 'b'], ['c', 'd']],
                  index=['row 1', 'row 2'],
                  columns=['col 1', 'col 2'])
# 输出 json 字符串
df.to_json(orient='split')
```

### HTML

read_html() 函数可以接受 HTML字符串 / html文件 / URL，并将HTML表解析为DataFrame。返回的是一个 df 列表，可以通知索引取第几个。

仅解析网页内 `<table>` 标签里的数据。

```python
dfs = pd.read_html('https://www.gairuo.com/p/pandas-io')
dfs[0] # 查看第一个 df
# 读取网页文件，第一行为表头
dfs = pd.read_html('data.html', header=0)
# 第一列为索引
dfs = pd.read_html(url, index_col=0)
# !!! 常用的功能与 read_csv 相同，可参考上文
```

如果一个网页表格很多，可以指定元素来取得：

```python
# id='table' 的表格，注意这儿仍然可能返回多个
dfs1 = pd.read_html(url, attrs={'id': 'table'})
# dfs1[0]
# class='sortable'
dfs2 = pd.read_html(url, attrs={'class': 'sortable'})
```

常用的参数使用与 [read_csv](https://www.gairuo.com/p/pandas-read-csv) 相同。

> **输出 html**

会输出 html 表格代码字符串。

```python
print(df.to_html())
print(df.to_html(columns=[0])) # 输出指定列
print(df.to_html(bold_rows=False)) # 表头不加粗体
# 表格指定样式，支持多个
print(df.to_html(classes=['class1', 'class2']))
```

### 剪贴板 Clipboard

剪贴板（Clipboard）是操作系统级的一个暂存数据的地方，它存在内存中，可以在不同软件之间传递，非常方便。pandas 支持读取剪贴板中的结构化数据，这就意味着我们不用将数据保存成文件，直接从网页、文件中复制，然后中直接读取，非常方便。

读取剪贴板，它的参数使用与 [read_csv](https://www.gairuo.com/p/pandas-read-csv) 完全一样：

```python
'''
  A B C
x 1 4 p
y 2 5 q
z 3 6 r
'''
# 复制上边的数据，然后直接赋值
cdf = pd.read_clipboard()
```

保存到剪贴板：

```python
# 执行完找个地方粘贴一下看看效果
df = pd.DataFrame({'A': [1, 2, 3],
                   'B': [4, 5, 6],
                   'C': ['p', 'q', 'r']},
                  index=['x', 'y', 'z'])
df.to_clipboard()
```

### SQL

Pandas 支持连接数据库进行查询，有以下几个方法：

- read_sql_table(table_name, con[, schema, …]), 把数据表里的数据转成 DataFrame
- read_sql_query(sql, con[, index_col, …]), 用 sql 查询数据到 DataFrame
- read_sql(sql, con[, index_col, …]), 同时支持上边两个功能
- DataFrame.to_sql(self, name, con[, schema, …])，把记录数据写到数据库里

```python
# 需要安装 sqlalchemy 库
from sqlalchemy import create_engine
# 创建数据库对象，sqlite 内存模式
engine = create_engine('sqlite:///:memory:')
# 把表名为 data 的表数据拿出来
with engine.connect() as conn, conn.begin():
    data = pd.read_sql_table('data', conn)

# data
# 将数据写入
data.to_sql('data', engine)
# 大量写入
data.to_sql('data_chunked', engine, chunksize=1000)
# 使用 sql 查询
pd.read_sql_query('SELECT * FROM data', engine)
# 使用 sql 查询后直接指定数据类型，1.3.0+
pd.read_sql_query('SELECT * FROM data', dtype={'a': np.float64, 'b': 'str', 'c': int})
```

### XML

Pandas 1.3.0 的 I/O 模块添加了 read_xml() 和 DataFrame.to_xml() 支持来读取和导出 XML 文档。它使用 lxml 作为解析器，XPath1.0 和 XSLT1.0 都可用。

> **读取 XML**

XML 文件读取的一个简单示例：

```python
xml = """<?xml version='1.0' encoding='utf-8'?>
<data>
 <row>
    <shape>square</shape>
    <degrees>360</degrees>
    <sides>4.0</sides>
 </row>
 <row>
    <shape>circle</shape>
    <degrees>360</degrees>
    <sides/>
 </row>
 <row>
    <shape>triangle</shape>
    <degrees>180</degrees>
    <sides>3.0</sides>
 </row>
 </data>"""

df = pd.read_xml(xml)
df
'''
      shape  degrees  sides
0    square      360    4.0
1    circle      360    NaN
2  triangle      180    3.0
'''
```

其他常用代码：

```
# 读取 URL
pd.read_xml("https://www.w3schools.com/xml/books.xml")
# 读取文件
with open(file_path, "r") as f:
    df = pd.read_xml(f.read())
# 将文件或者字符串加载为 StringIO / BytesIO，再读取
with open(file_path, "r") as f:
    sio = StringIO(f.read())
    # bio = BytesIO(f.read())bio = BytesIO(f.read())
df = pd.read_xml(sio)
# 从 AWS S3
df = pd.read_xml(
    "s3://irs-form-990/201923199349319487_public.xml",
    xpath=".//irs:Form990PartVIISectionAGrp",
    namespaces={"irs": "http://www.irs.gov/efile"}
)
# 使用 lxml 作为默认解析器，XPath 选择查询节点
pd.read_xml(file_path, xpath="//book[year=2005]")
# 仅读取元素或者属性
pd.read_xml(file_path, elems_only=True)
pd.read_xml(file_path, attrs_only=True)
```

> **生成 XML**

输出 XML 也非常方便，以下为示例：

```python
df.to_xml() # 输出 xml 字符
# 指定根节点和各行的标签名称
df.to_xml(root_name="geometry", row_name="objects")
# 编写以属性为中心(attribute-centric)的XML
df.to_xml(attr_cols=df.columns.tolist())
# <row index="0" name="Liver" team="E" Q1="89" Q2="21" Q3="24" Q4="64"/>
# 编写元素和属性的组合
(df.to_xml(
        index=False,
        attr_cols=['shape'],
        elem_cols=['degrees', 'sides'])
)
# 具有默认命名空间的 XML
df.to_xml(namespaces={"": "https://example.com"})
# 具有命名空间前缀的 XML
df.to_xml(namespaces={"doc": "https://example.com"},
                   prefix="doc")
# 编写不带声明或漂亮打印的XML
df.to_xml(xml_declaration=False,
                    pretty_print=False)
# XML和样式表转换，xsl 为样式字符串
df.to_xml(stylesheet=xsl)
```

> **输出** **Markdown**

[Markdown](https://www.gairuo.com/p/markdown-sheet) 是一种常用的技术文档编写语言，Pandas 支持输出 Markdown 格式字符串：

```python
print(df.to_markdown())
'''
|    |   A |   B | C   |
|:---|----:|----:|:----|
| x  |   1 |   4 | p   |
| y  |   2 |   5 | q   |
| z  |   3 |   6 | r   |
'''

# 不需要索引
print(df.to_markdown(index=False))
# 填充空值
print(df.fillna('').to_markdown(index=False))
```

## 索引 Indexing

### 认识索引

Pandas 数据的索引就像一本书的目录，让我们很快地找到想要看的章节，作为大量数据，创建合理的具有业务意义的索引对我们分析数据至关重要。

下图是一个简单的 DataFrame 中索引的示例：

![pandas index](https://www.gairuo.com/file/pic/2020/04/pandas_index_01.jpg)

其中：

- 行索引是数据的索引，列索引指向的是一个 Series
- DataFrame 的索引也是系列形成的 Series 的索引
- 建立索引让数据更加直观明确，如每行数据是针对一个国家的
- 建立索引方便数据处理
- 索引允许重复，但业务上一般不会让它重复

有时一个行和列层级较多的数据会出现[多层索引](https://www.gairuo.com/p/pandas-multiIndex) 的情况。

### 建立索引

之前我们学习了加载数据生成 DataFrame 时可以指定索引

```python
data = 'https://www.gairuo.com/file/data/dataset/team.xlsx'
df = pd.read_excel(data, index_col='name') # 设置索引为 name
df
'''
      team  Q1  Q2  Q3  Q4
name
Liver    E  89  21  24  64
Arry     C  36  37  37  57
Ack      A  57  60  18  84
Eorge    C  93  96  71  78
Oah      D  65  49  61  86
'''
```

如果加载时没有指定索引，我们可以使用 `df.set_index()` 指定：

```python
df.set_index('month') # 设置月份为索引
df.set_index(['month', 'year']) # 设置月份和年为多层索引
'''
            sale
month year
1     2012    55
4     2014    40
      2013    84
10    2014    31
'''

s = pd.Series([1, 2, 3, 4])
df.set_index(s) # 指定一个索引
df.set_index([s, 'year']) # 指定的索引和现有字段同时指定
df.set_index([s, s**2]) # 计算索引

# 其他的参数
df.set_index('month', drop=False) # 保留原列
df.set_index('month', append=True) # 保留原来的索引
df.set_index('month', inplace=True) # 建立索引并重写覆盖 df
```

### 索引类型

为了适应各种业务数据的处理，索引又针对各种类型数据定义了不同的索引类型：

> **数字索引 Numeric Index**

共有以下几种：

- RangeIndex: 单调整数范围的不可变索引。
- Int64Index: int64类型，有序可切片集合的不可变 ndarray。
- UInt64Index: 无符号整数标签的
- Float64Index: Float64 类型

```python
pd.Index([1, 2, 3])
# Int64Index([1, 2, 3], dtype='int64')
pd.RangeIndex(1,100,2)
# RangeIndex(start=1, stop=100, step=2)
pd.Int64Index([1,2,3,-4], name='num') # v2.0 将弃用
# Int64Index([1, 2, 3, -4], dtype='int64', name='num')
pd.UInt64Index([1,2,3,4]) # v2.0 将弃用
# UInt64Index([1, 2, 3, 4], dtype='uint64')
pd.Float64Index([1.2,2.3,3,4]) # v2.0 将弃用
# Float64Index([1.2, 2.3, 3.0, 4.0], dtype='float64')
```

> **类别索引 CategoricalIndex**

类别只能包含有限数量的（通常是固定的）可能值（类别）。 可以理解成枚举，比如性别只有男女，但在数据中每行都有，如果按文本处理会效率不高。类别的底层是 pandas.Categorical。

```python
pd.CategoricalIndex(['a', 'b', 'a', 'b'])
# CategoricalIndex(['a', 'b', 'a', 'b'], categories=['a', 'b'], ordered=False, dtype='category')
```

类别后边后有专门的讲解，只有在体量非常大的数据面前才能显示其优势。

> **间隔索引 IntervalIndex**

```python
pd.interval_range(start=0, end=5)
'''
IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],
              closed='right',
              dtype='interval[int64]')
'''
```

> **多层索引 MultiIndex**

教程后边会有专门的讲解。

```python
arrays = [[1, 1, 2, 2], ['red', 'blue', 'red', 'blue']]
pd.MultiIndex.from_arrays(arrays, names=('number', 'color'))
'''
MultiIndex([(1,  'red'),
            (1, 'blue'),
            (2,  'red'),
            (2, 'blue')],
           names=['number', 'color'])
'''
```

> **时间索引 DatetimeIndex**

```python
# 从一个日期连续到另一个日期
pd.date_range(start='1/1/2018', end='1/08/2018')
# 指定开始时间和周期
pd.date_range(start='1/1/2018', periods=8)
# 以月为周期
pd.period_range(start='2017-01-01', end='2018-01-01', freq='M')
# 周期嵌套
pd.period_range(start=pd.Period('2017Q1', freq='Q'),
                end=pd.Period('2017Q2', freq='Q'), freq='M')
```

> **时间差 TimedeltaIndex**

```python
pd.TimedeltaIndex(data =['06:05:01.000030', '+23:59:59.999999',
                         '22 day 2 min 3us 10ns', '+23:29:59.999999',
                         '+12:19:59.999999'])
# 使用 datetime
pd.TimedeltaIndex(['1 days', '1 days, 00:00:05',
                   np.timedelta64(2, 'D'),
                   datetime.timedelta(days=2, seconds=2)])
'''
TimedeltaIndex(['1 days 00:00:00', '1 days 00:00:05', '2 days 00:00:00',
                '2 days 00:00:02'],
               dtype='timedelta64[ns]', freq=None)
'''
```

> **周期索引 PeriodIndex**

```python
t = pd.period_range('2020-5-1 10:00:05', periods=8, freq='S')
pd.PeriodIndex(t,freq='S')
'''
PeriodIndex(['2020-05-01 10:00:05', '2020-05-01 10:00:06',
             '2020-05-01 10:00:07', '2020-05-01 10:00:08',
             '2020-05-01 10:00:09', '2020-05-01 10:00:10',
             '2020-05-01 10:00:11', '2020-05-01 10:00:12'],
            dtype='period[S]')
'''
```

### 索引对象

行和列的索引在 Pandas 里其实是一个 `Index` 对象，以下是创建一个 `index` 对象的方法：

> **创建对象**

```
pd.Index([1, 2, 3])
# Int64Index([1, 2, 3], dtype='int64')
pd.Index(list('abc'))
# Index(['a', 'b', 'c'], dtype='object')
# 可以定义一相 name
pd.Index(['e', 'd', 'a', 'b'], name='something')
```

> **查看**

```
df.index
# RangeIndex(start=0, stop=4, step=1)
df.columns
# Index(['month', 'year', 'sale'], dtype='object')
```

> **属性**

以下方法也适用于 `df.columns`, 因为都是 index 对象：

```
# 属性
df.index.name # 名称
df.index.array # array 数组
df.index.dtype # 数据类型
df.index.shape # 形状
df.index.size # 元素数量
df.index.values # array 数组
# 其他，不常用
df.index.empty # 是否为空
df.index.is_unique # 是否不重复
df.index.names # 名称列表
df.index.is_all_dates # 是否全是日期时间
df.index.has_duplicates # 是否有重复值
df.index.values # 索引的值 array
```

> **操作**

以下方法也适用于 `df.columns`, 因为都是 index 对象，有些也支持 Series：

```python
# 方法
df.index.astype('int64') # 转换类型
df.index.isin() # 是否存在，见下方示例
df.index.rename('number') # 修改索引名称
df.index.nunique() # 不重复值的数量
df.index.sort_values(ascending=False,) # 排序,倒序
df.index.map(lambda x:x+'_') # map 函数处理
df.index.str.replace('_', '') # str 替换
df.index.str.split('_') # 分隔
df.index.to_list() # 转为列表
df.index.to_frame(index=False, name='a') # 转成 DataFrame
df.index.to_series() # 转 series
df.index.to_numpy() # 转为 numpy
df.index.unique() # 去重
df.index.value_counts() # 去重及数量
df.index.where(df.index=='a') # 筛选
df.index.rename('grade', inplace=False) # 重命名索引名称
df.index.rename(['species', 'year']) # 多层，重命名索引名称
df.index.max() # 最大值
df.index.argmax() # 最大索引值
df.index.any()
df.index.all()
df.index.T # 转置，多层索引里很有用

# 其他，不常用
df.index.append(pd.Index([4,5])) # 追加
df.index.repeat(2) # 重复几次
df.index.inferred_type # 推测数据类型
df.index.hasnans # 有没有空值
df.index.is_monotonic_decreasing # 是否单调递减
df.index.is_monotonic # 是否单调递增
df.index.is_monotonic_increasing # 是否单调递增
df.index.nbytes # 基础数据中的字节数
df.index.ndim # 维度数，维数
df.index.nlevels # 索引层级数，通常为 1
df.index.min() # 最小值
df.index.argmin() # 最小索引值
df.index.argsort() # 顺序值组成的数组
df.index.asof(2) # 返回最近的索引
# numpy dtype or pandas type
df.index.astype('int64', copy=True) # 深拷贝
# 拷贝
df.index.copy(name='new', deep=True, dtype='int64')
df.index.delete(1) # 删除指定位置
# 对比不同
df.index.difference(pd.Index([1,2,4]), sort=False)
df.index.drop('a', errors='ignore') # 删除
df.index.drop_duplicates(keep='first') # 去重值
df.index.droplevel(0) # 删除层级
df.index.dropna(how='all') # 删除空值
df.index.duplicated(keep='first') # 重复值在结果数组中为True
df.index.equals(df.index) # 与另外一个索引对象是否相同
df.index.factorize() # 分解成（array:0-n, Index）
df.index.fillna(0, {0:'nan'}) # 填充空值
# 字符列表, 把 name 值加在第一位, 每个值加10
df.index.format(name=True, formatter=lambda x:x+10)

# 返回一个 array, 指定值的索引位数组，不在的为 -1
df.index.get_indexer([2,9])
# 获取 指定层级 Index 对象
df.index.get_level_values(0)
# 指定索引的位置，见示例
df.index.get_loc('b')
df.index.insert(2, 'f') # 在索引位 2 插入 f
df.index.intersection(df.index) # 交集
df.index.is_(df.index) # 类似 is 检查
df.index.is_categorical() # 是否分类数据
df.index.is_type_compatible(df.index) # 类型是否兼容
df.index.is_type_compatible(1) # 类型是否兼容

df.index.isna() # array 是否为空
df.index.isnull() # array 是否缺失值
df.index.join(df.index, how='left') # 连接
df.index.notna() # 是否不存在的值
df.index.notnull() # 是否不存在的值
df.index.ravel() # 展平值的ndarray
df.index.reindex(['a','b']) # 新索引 (Index,array:0-n)
df.index.searchsorted('f') # 如果插入这个值排序后在哪个索引位
df.index.searchsorted([0, 4]) # array([0, 3]) 多个
df.index.set_names('quarter') # 设置索引名称
df.index.set_names('species', level=0)
df.index.set_names(['kind', 'year'], inplace=True)
df.index.shift(10, freq='D') # 日期索引向前移动 10 天
idx1.symmetric_difference(idx2) # 两个索引不同的内容
idx1.union(idx2) # 拼接

df.add_prefix('t_') # 表头加前缀
df.add_suffix('_d') # 表头加后缀
df.first_valid_index() # 第一个有值的索引
df.last_valid_index() # 最后一个有值的索引

# 掩码设置的值的新索引, 小于 10 的变为 0
df.index.putmask(df.index<10, 0)
```

### 重置索引([reset_index](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reset_index.html?highlight=reset_index#pandas.DataFrame.reset_index) | [set_index](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.set_index.html?highlight=set_index#pandas.DataFrame.set_index))

有时我们想取消已有的索引，以重新来过，可以使用 `df.reset_index()`：

```python
df.reset_index() # 清除索引
df.set_index('month').reset_index() # 相当于啥也没干
# 删除原索引，month 列没了
df.set_index('month').reset_index(drop=True)
df2.reset_index(inplace=True) # 覆盖使生效
# year 一级索引取消
df.set_index(['month', 'year']).reset_index(level=1)
df2.reset_index(level='class') # 同上使用层级索引名
df.reset_index(level='class', col_level=1) # 列索引
# 不存在层级名称的填入指定名称
df.reset_index(level='class', col_level=1, col_fill='species')
```

如果想修改索引内容可以用`df.reindex(['a','b'])`，还能用它做指定排序。

### 索引重命名([rename](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html?highlight=rename#pandas.DataFrame.rename) | [set_axis](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.set_axis.html?highlight=set_axis#pandas.DataFrame.set_axis))

对行和列的索引名进行修改。

```python
# 一一对应修改列索引
df.rename(columns={"A": "a", "B": "c"})
df.rename(str.lower, axis='columns')
# 修改行索引
df.rename(index={0: "x", 1: "y", 2: "z"})
df.rename({1: 2, 2: 4}, axis='index')
# 修改数据类型
df.rename(index=str)
# 重新修改索引
replacements = {l1:l2 for l1, l2 in zip(list1, list2)}
df.rename(replacements)
# 列名加前缀
df.rename(lambda x:'t_' + x, axis=1)
# 利用 iter() 函数的 next 特性修改
df.rename(lambda x, y=iter('abcdef'): next(y), axis=1)
# 修改列名，用解包形式生成新旧字段字典
df.rename(columns=dict(zip(df, list('abcd'))))
```

`df.set_axis` 可以将所需的索引分配给给定的轴。可以通过分配类似列表或索引的方式来更改列标签或行标签的索引。

```python
# 修改索引
df.set_axis(['a', 'b', 'c'], axis='index')
# 修改列名
df.set_axis(list('abcd'), axis=1)
# 使修改生效
df.set_axis(['a', 'b'], axis='columns', inplace=True)
# 传入索引内容
df.set_axis(pd.Index(list('abcde')), axis=0)
```

### 索引名重命名([rename_axis](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename_axis.html?highlight=rename_axis#pandas.DataFrame.rename_axis))

注意，这是修改索引的名称，不是索引或者列名本身：

```python
s.rename_axis("animal") # 索引重命名
df.rename_axis(["dow", "hr"]) # 多层索引索引名修改
df.rename_axis('info', axis="columns") # 修改行索引名
# 修改多层行索引名
df.rename_axis(index={'a': 'A', 'b': 'B'})
# 修改多层列索引名
df.rename_axis(columns={'name': 's_name', 'b': 'B'})
df.rename_axis(columns=str.upper) # 行索引名变大写
```

### 部分实例

```python
# idx.isin() 是否存在
idx = pd.Index([1,2,3])
df.index.isin(idx)
# array([False, False, False, False])
df.index.isin(['a','b'])
# array([ True,  True, False, False])
midx = pd.MultiIndex.from_arrays([[1,2,3],
                                 ['red', 'blue', 'green']],
                                 names=('number', 'color'))
midx.isin([(1, 'red'), (3, 'red')])
# array([ True, False, False])
dates = ['2000-03-11', '2000-03-12', '2000-03-13']
dti = pd.to_datetime(dates)
dti.isin(['2000-03-11'])
# array([ True, False, False])

# i.argsort() 排序
# 将对索引进行排序的整数索引，见下文示例
idx = pd.Index(['b', 'a', 'd', 'c'])
order = idx.argsort() # array([1, 0, 3, 2])
idx[order] # Index(['a', 'b', 'c', 'd'], dtype='object')

# i.asof(2) 返回最近的索引, 支持日期，可实现找最近日期
# 从索引中返回标签；如果不存在，则返回前一个标签
idx2 = pd.Index([1,3,6])
idx2.asof(5) # 3
idx2.asof(6) # 5
idx2.asof(-1) # nan

# index.get_loc 指定索引的位置，见示例
unique_index = pd.Index(list('abc'))
unique_index.get_loc('b') # 1
monotonic_index = pd.Index(list('abbc'))
monotonic_index.get_loc('b') # slice(1, 3, None)
non_monotonic_index = pd.Index(list('abcb'))
non_monotonic_index.get_loc('b')
# array([False,  True, False,  True], dtype=bool)
```

更多的操作可以看[官方文档](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Index.html)。

### 重复索引

注：Pandas 版本要求 1.2.0+，这是一项实验功能

Pandas 默认地行列索引对象不需要唯一，可以有重复的行或列标签。但有时候比如通过 SQL 将数据存入数据库，就不能有重复的索引和列名，我们可以通过设置来限制重复索引：

```python
df = pd.DataFrame({"A": [1, 2]}, index=['a', 'a'])
# 默认是允许重复的
df.flags["allows_duplicate_labels"] # True
df.flags.allows_duplicate_labels # True
df.flags
# <Flags(allows_duplicate_labels=True)>

# 已重复的就不能再设置为不重复的了
df.flags.allows_duplicate_labels = False
# DuplicateLabelError: Index has duplicates. positions....

# 生成时设置为标签为不可重复，后继操作就不能有重复的索引了
s = (pd.Series([1, 2], index=['a', 'b'])
 .set_flags(allows_duplicate_labels=False)
)
s.reindex(['a', 'a'])
# DuplicateLabelError: Index has duplicates...
```

### 索引操作总结([reindex](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reindex.html?highlight=reindex#pandas.DataFrame.reindex))

DataFrame 是二维的，有两个轴（axis，横向 1 或者纵向 0），每个方向上都有索引。索引都有名字（name，索引名），特别是在多层索引下，name 就显得特别重要。索引的取值索引值（标签值，label）是索引上每个行和列的具体值，也可叫标签值，有时简称标签。我们统一称索引名和索引值吧。基于此，总结下操作：

- df.set_index()：将不是索引的设置为索引，只能按列设置
- df.reset_index()：将所有（也可部分）的索引去除，恢复到自然索引（0-n）值
- df.rename()：修改行列的索引值，要提供原有的索引值
- df.set_axis()：将所需索引值指定给指定轴，不需要原有的索引值
- df.rename_axis()：设置轴的索引名
- [df.reindex()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reindex.html?highlight=reindex#pandas.DataFrame.reindex)：对现有的索引按给定的索引值顺序排列，如不存在的值为 Nan，支持缺失值填充方法
- df.reindex_like()：取其他表的索引值作为自己的索引值，相当于 `df.reindex(index=other.index, columns=other.columns,...)`
- df.sort_index()：按索引值（可指定轴）对数据进行排序

### 索引操作方法对比

我们用表格对几个修改索引名和索引值的方法进行对比：

| 方法                | 可按轴 axis | 修改索引名 name | 修改索引值 label | 是否需要原值 | 其他功能       |
| ------------------- | ----------- | --------------- | ---------------- | ------------ | -------------- |
| `df.rename()`       | 是          | -               | 是               | 是           | nan            |
| `df.set_axis()`     | 是          | -               | 是               | -            | nan            |
| `df.rename_axis()`  | 是          | 是              | -                | 可有可无     | 支持映射       |
| `df.reindex()`      | 是          | -               | 是               | -            | 支持缺失值填充 |
| `df.reindex_like()` | 必须同时    | -               | 是               | -            | 支持缺失值填充 |

## 数据的信息

### 查看样本

```pyhton
df = pd.read_excel('https://www.gairuo.com/file/data/team.xlsx')
s = df.Q1 # 取其中一列，形成 Series
df.head() # 查看前五条数据
'''
    name team  Q1  Q2  Q3  Q4
0  Liver    E  89  21  24  64
1   Arry    C  36  37  37  57
2    Ack    A  57  60  18  84
3  Eorge    C  93  96  71  78
4    Oah    D  65  49  61  86
'''
```

其他：

```python
df.head(10) # 查看前10条数据
df.tail() # 查看后五条数据
df.tail(10) # 查看后10条数据
df.sample() # 随机查看一条数据
df.sample(3) # 随机查看3条数据
df.sample(10, ignore_index=True) # 随机后重置索引
```

### 形状 df.shape

`df.shape` 会返回一个数组，第一个代表行数，第二个代表列数，这就是这个数据的基本形状，也是数据的大小。

```python
df.shape
# (100, 6)
# 共 100 行，6列 (索引不算)

# Series 只有一个值
s.shape
# (100,)
```

### 基本信息 df.info()

`df.info()` 显示有数据类型、索引情况、行列数、各字段数据类型、内存占用等。Series 不支持。

```python
df.info()
'''
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 100 entries, 0 to 99
Data columns (total 6 columns):
 #   Column  Non-Null Count  Dtype
---  ------  --------------  -----
 0   name    100 non-null    object
 1   team    100 non-null    object
 2   Q1      100 non-null    int64
 3   Q2      100 non-null    int64
 4   Q3      100 non-null    int64
 5   Q4      100 non-null    int64
dtypes: int64(4), object(2)
memory usage: 4.8+ KB
'''
```

### 数据类型 df.dtypes

会返回每个字段的数据类型。

```python
df.dtypes
'''
name    object
team    object
Q1       int64
Q2       int64
Q3       int64
Q4       int64
dtype: object
'''
```

如果是 Series 需要用 `s.dtype`

```python
s.dtype
# dtype('int64')
```

### 行列索引内容 df.axes

会返回一个列内容和行内容组成的列表 [列索引, 行索引]。

```python
df.axes
'''
[RangeIndex(start=0, stop=100, step=1),
 Index(['name', 'team', 'Q1', 'Q2', 'Q3', 'Q4'], dtype='object')]
'''
```

Series 只显示列索引，就是它的索引：

```python
s.axes
# [RangeIndex(start=0, stop=100, step=1)]
```

### 其他信息

注：以下信息操作，DataFrame 和 Series 一般都支持。

```python
# 索引对象
df.index
# RangeIndex(start=0, stop=100, step=1)
# 列索引，Series 不支持
df.columns
# Index(['name', 'team', 'Q1', 'Q2', 'Q3', 'Q4'], dtype='object')
df.values # 建议使用 to_numpy()
df.to_numpy() # numpy array(<所有值的列表矩阵>)
df.ndim # 2 维度数
df.size # 600 行x列的总数，就是总共有多少数据
# 是否为空，注意有空值不认为是空
df.empty # False
# Series 的索引, DataFrame 的列名
dfs.keys()
# 返回第一个非NA/空值的索引
df.first_valid_index() # 0
# 返回最后一个非NA/空值的索引
df.last_valid_index() # 99

# 数据的标记信息（目前只支持是否重复标签）pd 1.2.0+
df.flags
# <Flags(allows_duplicate_labels=True)>
# 设置元信息，可用于数据基础信息描述
df.attrs={'info': '学生成绩表'}
# 查看元信息
df.attrs # {'info': '学生成绩表'}
# 标签是否允许重复
df.flags["allows_duplicate_labels"]
df.flags.allows_duplicate_labels # True
df.set_flags(allows_duplicate_labels=False) # 设置
```

此外 Series 独有的如下：

```python
s.name # 'Q1'
s.array # 值组成的数组 <PandasArray>
s.dtype # 类型，dtype('int64')
s.hasnans # False 是否有空
```

`.name` 可获取索引的名称，需要区分的是上例数据中 `df.name` 也能正常执行，它其实是 df 调用数据字段的方法，因为正好有名为 name 的列，如果没有就会报错，DataFrame 是没有此属性的。

## 数学统计

Pandas 可以对 Series 与 DataFrame 进行快速的描述性统计，如求和、平均数、最大值、方差等，是最基础也是最实用的统计方法。

注：本文所使用的 `df` 和 `s` 是[数据信息](https://www.gairuo.com/p/pandas-data-info)一文中的数据。

### 数据总结（df.describe())

会返回一个有多个行的所有数字列的统计表，每个行是一个统计指标，有总数、平均数、标准差、最大最小值、四分位数等，对我们初步了解数据还是很有作用。

```python
df.describe()
'''
               Q1          Q2          Q3          Q4
count  100.000000  100.000000  100.000000  100.000000
mean    49.200000   52.550000   52.670000   52.780000
std     29.962603   29.845181   26.543677   27.818524
min      1.000000    1.000000    1.000000    2.000000
25%     19.500000   26.750000   29.500000   29.500000
50%     51.500000   49.500000   55.000000   53.000000
75%     74.250000   77.750000   76.250000   75.250000
max     98.000000   99.000000   99.000000   99.000000
'''
```

如果无数字：

```python
pd.Series(['a', 'b', 'c', 'c']).describe()
'''
count     4
unique    3
top       c
freq      2
dtype: object
'''
```

如果是一个时间类型则会按时间相关的如开始结束时间、周期等信息。

```python
s2 = pd.Series([
  np.datetime64("2000-01-01"),
  np.datetime64("2010-01-01"),
  np.datetime64("2010-02-01")
])

s2.describe()
'''
count                       3
unique                      3
top       2000-01-01 00:00:00
freq                        1
first     2000-01-01 00:00:00
last      2010-02-01 00:00:00
dtype: object
'''

# 1.1 的用法
(
    pd.Series(pd.date_range('2000-01-01', '2000-05-01'))
    .describe(datetime_is_numeric=True)
)
```

还可以自己指定分位数（一般情况下，默认值包含中位数）等：

```python
df.describe(percentiles=[.05, .25, .75, .95])
df.describe(include=[np.object, np.number]) # 指定类型
df.describe(exclude =[np.object]) # 排除类型
```

### 数学统计

数学计算是最常见的统计方法，比如我们要知道列的平均数据：

```python
df.mean()
'''
Q1    49.20
Q2    52.55
Q3    52.67
Q4    52.78
dtype: float64
'''

# 看每行
df.mean(1).head()
'''
0    49.50
1    41.75
2    54.75
3    84.50
4    65.25
dtype: float64
'''

# Q1 列的平均值
df.Q1.mean()
# 49.2
```

一般 DataFrame 计算后为一个 Series，Series 计算后为一个定值。

### 统计函数

Pandas 内置很多数学计算方法：

```python
df.mean() # 返回所有列的均值
df.mean(1) # 返回所有行的均值，下同
df.corr() # 返回列与列之间的相关系数
df.count() # 返回每一列中的非空值的个数
df.max() # 返回每一列的最大值
df.min() # 返回每一列的最小值
df.abs() # 绝对值
df.median() # 返回每一列的中位数
df.std() # 返回每一列的标准差, 贝塞尔校正的样本标准偏差
df.var() # 无偏方差
df.sem() # 平均值的标准误差
df.mode() # 众数
df.prod() # 连乘
df.mad() # 平均绝对偏差
df.cumprod() # 累积连乘,累乘
df.cumsum(axis=0) # 累积连加,累加
df.nunique() # 去重数量，不同值的量
df.idxmax() # 每列最大的值的索引名
df.idxmin() # 最小
df.cummax() # 累积最大值
df.cummin() # 累积最小值
df.skew() # 样本偏度 (第三阶)
df.kurt() # 样本峰度 (第四阶)
df.quantile() # 样本分位数 (不同 % 的值)
```

一些特殊的说明：

```python
# 很多支持指定行列（默认是 axis=0 列）等参数
df.mean(1) # 按行计算
# 很多支持
df.sum(0, skipna=False) # 否要排除缺失数据
# 很多支持
df.sum(level='blooded') # 索引级别
df.sum(level=0)
# 如果有空值总共算几
df.sum(min_count=1)
# 按行计算，只计算数字类型
df.sum(1, numeric_only=True)

# 可自定义相关性函数
def histogram_intersection(a, b):
    v = np.minimum(a, b).sum().round(decimals=1)
    return v
df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)],
                  columns=['dogs', 'cats'])
df.corr(method=histogram_intersection)
```

这些函数都是我们今后用于统计计算的基础。

## 求值操作

除了简单的数学统计外，我们往往对数据还需要做非统计性计算，如去重、格式化等等，接下来我们将介绍一些数据的加工处理方法。

注：本文所使用的 `df` 和 `s` 是[数据信息](https://www.gairuo.com/p/pandas-data-info)一文中的数据。

### 位置差值 ([df.diff](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.diff.html?highlight=df%20diff) | [s.shift]())

df.diff() 可以做位置差操作，经常用在一个序列性数据中上下一个数据之间的差值，如增量研究。

```python
# 本行与前一行的差值（即当前值比上一行增加了多少）
# 无前一行的本行值为 NaN
df.diff()
df.diff(axis=1) # 向右一列
df.diff(2)
df.diff(-1) # 新的本行为本行减去后一行
```

`df.shift()` 可以对数据进行移位，不做任何计算，移动后目标位置的类型无法接收收的为 `NaN`。

```python
# 整体下移一行，最顶的一行为 NaN
df.shift()
df.shift(3) # 移三行
# 整体上移一行，最底的一行为 NaN
df.Q1.head().shift(-1)
# 向右移动一位
df.shift(axis=1)
df.shift(3, axis=1) # 移三位
# 向左移动一位
df.shift(-1, axis=1)
# 实现了 df.Q1.diff()
df.Q1 - df.Q1.shift()
```

### 常用函数

```pyhton
df.all() # 返回所有列all()值的Series
df.any()

# 用表达式计算生成列。仅支持列，不是太安全
df.eval('Q2Q3 = Q2 + Q3')
df.eval('Q2Q3 = Q2 + Q3', inplace=True) # 替换生效

# 四舍五入
df.round(2) # 指定字段指定保留小数位，如有
df.round({'Q1': 2, 'Q2': 0})
df.round(-1) # 保留10位

# 每个列的去重值的数量
df.nunique()
s.nunique() # 本列的去重值

# 真假检测
df.isna() # 值的真假值替换
df.notna() # 与上相反
```

对 df 整体所有元素做加减乘除等计算：

```python
df + 1 # 等运算
df.add() # 加
df.sub() # 减
df.mul() # 乘
df.div() # 除
df.divmod() # 返回 (a // b, a % b)
df.truediv() # Divide DataFrames (float division).
df.floordiv() # Divide DataFrames (integer division).
df.mod() # 模，除后的余数
df.pow() # 指数幂
df.dot(df2) # 矩阵运算
```

### 数据降维([df | s.squeeze()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.squeeze.html?highlight=squeeze))

[squeeze()](https://www.gairuo.com/p/pandas-squeeze) 可以实现数据从 DataFrame 降至 Series，再降到标量，完成数据挤压。如果是单列（行），挤压为 Series，单个值直接挤压为标量。

```python
# 单列 DataFrame 转为 Series
df[['Q1']].squeeze()
# 单值 DataFrame 和 Series 转为标量
df.loc[1, 2].squeeze() # 36
df.loc[df.index==5, ['name']].squeeze() # 'Harlie'
df.Q1.head(1).squeeze() # 89

# 单值 DataFrame 挤压为行或列 Series
df.loc[df.index==5, ['name']].squeeze('columns')
'''
5    Harlie
Name: name, dtype: object
'''
df.loc[df.index==5, ['name']].squeeze('rows')
'''
name    Harlie
Name: 5, dtype: object
'''
```

### Series 专门函数

## 专门函数

```python
# 不重复的值及数量
s.value_counts()
df.value_counts()
s.value_counts(normalize=True) # 重复值的频率
s.value_counts(normalize=True)*100 # 当前值在序列中的百分比
s.value_counts(sort=False) # 不按频率排序

s.unique() # 去重的值 array
s.is_unique # 是否有重复

# 最大最小值
s.nlargest() # 最大的前5个
s.nlargest(15) # 最大的前15个
s.nsmallest() # 最小的前5个
s.nsmallest(15) # 最小的前15个

s.pct_change() # 计算与前一行的变化百分比
df.pct_change()
s.pct_change(periods=2) # 前两行

s1.cov(s2) # 两个序列的协方差
```

## 查询筛选数据

## 数据类型转换

## 数据排序

## 删除数据

## 数据迭代

## 函数应用



